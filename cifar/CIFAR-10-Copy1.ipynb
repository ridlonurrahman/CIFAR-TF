{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10, cifar_input, cifar_input_ver2\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "'''tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10VGG_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 25000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")'''\n",
    "\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.005       # Initial learning rate.\n",
    "\n",
    "max_steps = 200000\n",
    "train_dir = 'cifar10VGGdropout_train/'\n",
    "batch_size = 128\n",
    "log_device_placement = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  # labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "          logits=logits, labels=labels, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  return loss_averages_op\n",
    "\n",
    "def train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / 128\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    dtype = tf.float16 if 0 else tf.float32\n",
    "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if 0 else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n",
    "\n",
    "def inference(images, training=True):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "\n",
    "  # CONV 1\n",
    "  with tf.variable_scope('conv1_1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  with tf.variable_scope('conv1_2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  pool1 = tf.nn.max_pool(conv1_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "\n",
    "  if training==True:\n",
    "    keep_prob = 0.9\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout_p1 = tf.nn.dropout(pool1, keep_prob)\n",
    "\n",
    "  # CONV 2\n",
    "  with tf.variable_scope('conv2_1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 64, 128],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(dropout_p1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [128], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  with tf.variable_scope('conv2_2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 128, 128],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [128], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  pool2 = tf.nn.max_pool(conv2_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool2')\n",
    "\n",
    "  if training==True:\n",
    "    keep_prob = 0.9\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout_p2 = tf.nn.dropout(pool2, keep_prob)\n",
    "\n",
    "  # CONV 3\n",
    "  with tf.variable_scope('conv3_1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 128, 256],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(dropout_p2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv3_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  with tf.variable_scope('conv3_2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 256, 256],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv3_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  pool3 = tf.nn.max_pool(conv3_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool3')\n",
    "\n",
    "  if training==True:\n",
    "    keep_prob = 0.9\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout_p3 = tf.nn.dropout(pool3, keep_prob)\n",
    "\n",
    "  # CONV 4\n",
    "  with tf.variable_scope('conv4_1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 256, 512],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(dropout_p3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [512], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv4_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  with tf.variable_scope('conv4_2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 512, 512],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [512], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv4_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  pool4 = tf.nn.max_pool(conv4_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool4')\n",
    "\n",
    "  if training==True:\n",
    "    keep_prob = 0.9\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout_p4 = tf.nn.dropout(pool4, keep_prob)\n",
    "\n",
    "  # CONV 5\n",
    "  with tf.variable_scope('conv5_1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 512, 512],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(dropout_p4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [512], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv5_1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  with tf.variable_scope('conv5_2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[3, 3, 512, 512],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [512], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv5_2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "  pool5 = tf.nn.max_pool(conv5_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool5')\n",
    "\n",
    "  if training==True:\n",
    "    keep_prob = 0.75\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout1 = tf.nn.dropout(pool5, keep_prob)\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(dropout1, [128, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 1024],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "  \n",
    "  if training==True:\n",
    "    keep_prob = 0.5\n",
    "  else:\n",
    "    keep_prob = 1\n",
    "  dropout2 = tf.nn.dropout(local3, keep_prob)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[1024, 1024],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(dropout2, weights) + biases, name=scope.name)\n",
    "  \n",
    "  dropout3 = tf.nn.dropout(local4, keep_prob)\n",
    "\n",
    "  # linear layer(WX + b),\n",
    "  # We don't apply softmax here because \n",
    "  # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits \n",
    "  # and performs the softmax internally for efficiency.\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [1024, NUM_CLASSES],\n",
    "                                          stddev=1/1024.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(dropout3, weights), biases, name=scope.name)\n",
    "\n",
    "  return softmax_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 17:41:50.867100: step 0, loss = 6.28 (26.6 examples/sec; 4.811 sec/batch)\n",
      "2017-03-09 17:41:53.454680: step 10, loss = 6.62 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:41:56.787997: step 20, loss = 6.26 (374.1 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:42:00.140402: step 30, loss = 6.19 (366.0 examples/sec; 0.350 sec/batch)\n",
      "2017-03-09 17:42:03.430549: step 40, loss = 6.20 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:42:06.694231: step 50, loss = 6.20 (399.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:42:10.008354: step 60, loss = 6.20 (375.8 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:42:13.303450: step 70, loss = 6.20 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:42:16.615618: step 80, loss = 6.18 (394.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:42:19.947086: step 90, loss = 6.18 (375.2 examples/sec; 0.341 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04802\n",
      "2017-03-09 17:42:23.274304: step 100, loss = 6.18 (367.7 examples/sec; 0.348 sec/batch)\n",
      "2017-03-09 17:42:26.580541: step 110, loss = 6.16 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:42:29.889547: step 120, loss = 6.21 (400.2 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:42:33.186635: step 130, loss = 6.19 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:42:36.488236: step 140, loss = 6.17 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:42:39.826751: step 150, loss = 6.18 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:42:43.108697: step 160, loss = 6.18 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:42:46.424317: step 170, loss = 6.19 (373.5 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 17:42:49.742857: step 180, loss = 6.17 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:42:53.031399: step 190, loss = 6.20 (395.1 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.02623\n",
      "2017-03-09 17:42:56.317686: step 200, loss = 6.16 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:42:59.643828: step 210, loss = 6.14 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:43:02.935616: step 220, loss = 6.15 (369.9 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 17:43:06.209551: step 230, loss = 6.15 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:43:09.488087: step 240, loss = 6.16 (385.7 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:43:12.798251: step 250, loss = 6.14 (382.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:43:16.086553: step 260, loss = 6.13 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:43:19.396745: step 270, loss = 6.14 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:43:22.704783: step 280, loss = 6.16 (408.3 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 17:43:26.025844: step 290, loss = 6.14 (417.6 examples/sec; 0.306 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.02952\n",
      "2017-03-09 17:43:29.327490: step 300, loss = 6.17 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:43:32.627540: step 310, loss = 6.12 (370.4 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 17:43:35.950399: step 320, loss = 6.12 (392.6 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:43:39.263864: step 330, loss = 6.11 (378.6 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:43:42.546571: step 340, loss = 6.10 (370.9 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 17:43:45.884537: step 350, loss = 6.11 (382.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:43:49.205206: step 360, loss = 6.12 (383.2 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:43:52.514899: step 370, loss = 6.09 (372.2 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 17:43:55.808894: step 380, loss = 6.10 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:43:59.107785: step 390, loss = 6.03 (402.7 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.02196\n",
      "2017-03-09 17:44:02.417521: step 400, loss = 6.06 (405.1 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:44:05.721445: step 410, loss = 5.99 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:44:09.027453: step 420, loss = 5.98 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:44:12.317643: step 430, loss = 6.00 (401.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:44:15.646392: step 440, loss = 6.04 (371.7 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 17:44:18.936456: step 450, loss = 6.01 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:44:22.245380: step 460, loss = 5.96 (385.5 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:44:25.540700: step 470, loss = 5.99 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:44:28.868198: step 480, loss = 5.92 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:44:32.168642: step 490, loss = 5.97 (377.3 examples/sec; 0.339 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.02498\n",
      "2017-03-09 17:44:35.476872: step 500, loss = 5.95 (373.3 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 17:44:38.771123: step 510, loss = 5.94 (386.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:44:42.061741: step 520, loss = 5.93 (376.8 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 17:44:45.351854: step 530, loss = 5.93 (381.2 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:44:48.626703: step 540, loss = 5.98 (401.4 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:44:51.907529: step 550, loss = 5.99 (400.9 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:44:55.198415: step 560, loss = 5.93 (402.5 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 17:44:58.475579: step 570, loss = 5.88 (382.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:45:01.761062: step 580, loss = 5.89 (365.1 examples/sec; 0.351 sec/batch)\n",
      "2017-03-09 17:45:05.055090: step 590, loss = 5.79 (389.8 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04128\n",
      "2017-03-09 17:45:08.358168: step 600, loss = 5.89 (371.5 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 17:45:11.648026: step 610, loss = 5.81 (378.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:45:14.937129: step 620, loss = 5.84 (400.3 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:45:18.242972: step 630, loss = 5.89 (374.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:45:21.532919: step 640, loss = 5.94 (400.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:45:24.821551: step 650, loss = 5.85 (395.0 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:45:28.134388: step 660, loss = 5.91 (377.4 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:45:31.401881: step 670, loss = 5.86 (393.6 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:45:34.687027: step 680, loss = 5.88 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:45:37.979551: step 690, loss = 5.92 (377.6 examples/sec; 0.339 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0369\n",
      "2017-03-09 17:45:41.286462: step 700, loss = 5.85 (377.1 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:45:44.585161: step 710, loss = 5.79 (366.2 examples/sec; 0.350 sec/batch)\n",
      "2017-03-09 17:45:47.871024: step 720, loss = 5.78 (383.4 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:45:51.180125: step 730, loss = 5.81 (371.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 17:45:54.465657: step 740, loss = 5.96 (399.0 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:45:57.757808: step 750, loss = 5.95 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:46:01.059400: step 760, loss = 5.72 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:46:04.357738: step 770, loss = 5.73 (398.8 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:46:07.656987: step 780, loss = 5.65 (379.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:46:10.934995: step 790, loss = 5.90 (393.7 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03457\n",
      "2017-03-09 17:46:14.240137: step 800, loss = 5.80 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:46:17.545111: step 810, loss = 5.80 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:46:20.841670: step 820, loss = 5.77 (379.1 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:46:24.119942: step 830, loss = 5.70 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:46:27.417172: step 840, loss = 5.72 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:46:30.712348: step 850, loss = 5.82 (391.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:46:34.037876: step 860, loss = 5.75 (388.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:46:37.361991: step 870, loss = 5.84 (375.6 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:46:40.629113: step 880, loss = 5.70 (390.1 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:46:43.919279: step 890, loss = 5.72 (382.2 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03346\n",
      "2017-03-09 17:46:47.203811: step 900, loss = 5.69 (391.1 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:46:50.471366: step 910, loss = 5.83 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:46:53.746420: step 920, loss = 5.71 (379.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:46:57.031688: step 930, loss = 5.74 (404.9 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:47:00.317069: step 940, loss = 5.82 (386.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:47:03.610156: step 950, loss = 5.77 (382.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:47:06.892286: step 960, loss = 5.73 (397.8 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:47:10.198337: step 970, loss = 5.76 (381.2 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:47:13.489846: step 980, loss = 5.63 (404.1 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 17:47:16.797290: step 990, loss = 5.72 (392.7 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03797\n",
      "2017-03-09 17:47:20.122708: step 1000, loss = 5.77 (377.6 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:47:23.405109: step 1010, loss = 5.82 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:47:26.696595: step 1020, loss = 5.72 (389.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:47:30.002816: step 1030, loss = 5.67 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:47:33.303978: step 1040, loss = 5.66 (382.9 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:47:36.602429: step 1050, loss = 5.85 (380.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:47:39.923315: step 1060, loss = 5.75 (392.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:47:43.207828: step 1070, loss = 5.75 (400.9 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:47:46.501197: step 1080, loss = 5.68 (401.0 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:47:49.762989: step 1090, loss = 5.69 (409.0 examples/sec; 0.313 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03595\n",
      "2017-03-09 17:47:53.061544: step 1100, loss = 5.68 (400.3 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:47:56.341128: step 1110, loss = 5.81 (399.8 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:47:59.665423: step 1120, loss = 5.82 (367.5 examples/sec; 0.348 sec/batch)\n",
      "2017-03-09 17:48:02.934298: step 1130, loss = 5.70 (403.6 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 17:48:06.244882: step 1140, loss = 5.78 (374.0 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:48:09.502041: step 1150, loss = 5.67 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:48:12.796040: step 1160, loss = 5.67 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:48:16.099394: step 1170, loss = 6.01 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:48:19.389505: step 1180, loss = 5.56 (371.5 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 17:48:22.681482: step 1190, loss = 5.80 (392.7 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03764\n",
      "2017-03-09 17:48:25.979479: step 1200, loss = 5.64 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:48:29.282878: step 1210, loss = 5.63 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:48:32.570674: step 1220, loss = 5.71 (375.7 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:48:35.883398: step 1230, loss = 5.65 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:48:39.163245: step 1240, loss = 5.64 (374.1 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:48:42.466178: step 1250, loss = 5.61 (372.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 17:48:45.784229: step 1260, loss = 5.76 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:48:49.074444: step 1270, loss = 5.69 (391.1 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:48:52.383396: step 1280, loss = 5.60 (382.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:48:55.653490: step 1290, loss = 5.56 (403.7 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03255\n",
      "2017-03-09 17:48:58.954821: step 1300, loss = 5.63 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:49:02.239995: step 1310, loss = 5.68 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:49:05.525649: step 1320, loss = 5.60 (391.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:49:08.827890: step 1330, loss = 5.55 (379.9 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:49:12.112286: step 1340, loss = 5.55 (379.1 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:49:15.393241: step 1350, loss = 5.56 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:49:18.697782: step 1360, loss = 5.49 (404.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:49:22.012283: step 1370, loss = 5.68 (380.9 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:49:25.306295: step 1380, loss = 5.72 (379.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:49:28.610646: step 1390, loss = 5.73 (381.0 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03675\n",
      "2017-03-09 17:49:31.885144: step 1400, loss = 5.52 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:49:35.171192: step 1410, loss = 5.63 (390.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:49:38.475277: step 1420, loss = 5.78 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:49:41.764655: step 1430, loss = 5.54 (399.0 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:49:45.026144: step 1440, loss = 5.53 (396.5 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:49:48.322888: step 1450, loss = 5.53 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:49:51.591633: step 1460, loss = 5.50 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:49:54.871105: step 1470, loss = 5.58 (380.1 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:49:58.140212: step 1480, loss = 5.54 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:50:01.426552: step 1490, loss = 5.69 (405.4 examples/sec; 0.316 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04402\n",
      "2017-03-09 17:50:04.736286: step 1500, loss = 5.55 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:50:08.038583: step 1510, loss = 5.60 (399.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:50:11.340256: step 1520, loss = 5.53 (389.3 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:50:14.647561: step 1530, loss = 5.61 (378.0 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:50:17.928190: step 1540, loss = 5.72 (383.2 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:50:21.205838: step 1550, loss = 5.55 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:50:24.503522: step 1560, loss = 5.59 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:50:27.778970: step 1570, loss = 5.58 (376.6 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 17:50:31.071512: step 1580, loss = 5.43 (371.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 17:50:34.364352: step 1590, loss = 5.77 (381.1 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03659\n",
      "2017-03-09 17:50:37.668418: step 1600, loss = 5.53 (369.6 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 17:50:40.957569: step 1610, loss = 5.50 (389.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:50:44.254057: step 1620, loss = 5.53 (377.7 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:50:47.525771: step 1630, loss = 5.51 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:50:50.839931: step 1640, loss = 5.58 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:50:54.144456: step 1650, loss = 5.42 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:50:57.405968: step 1660, loss = 5.58 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:51:00.720452: step 1670, loss = 5.53 (382.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:51:04.006416: step 1680, loss = 5.61 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:51:07.293312: step 1690, loss = 5.59 (405.5 examples/sec; 0.316 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03414\n",
      "2017-03-09 17:51:10.627810: step 1700, loss = 5.46 (375.0 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:51:13.932893: step 1710, loss = 5.60 (388.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:51:17.222530: step 1720, loss = 5.55 (366.9 examples/sec; 0.349 sec/batch)\n",
      "2017-03-09 17:51:20.500567: step 1730, loss = 5.45 (408.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 17:51:23.813163: step 1740, loss = 5.69 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:51:27.118223: step 1750, loss = 5.48 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:51:30.377319: step 1760, loss = 5.50 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:51:33.670319: step 1770, loss = 5.49 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:51:36.962997: step 1780, loss = 5.43 (380.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:51:40.268114: step 1790, loss = 5.36 (395.3 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03537\n",
      "2017-03-09 17:51:43.571137: step 1800, loss = 5.46 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:51:46.852933: step 1810, loss = 5.41 (390.5 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:51:50.139137: step 1820, loss = 5.45 (380.6 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1822 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 17:51:53.465916: step 1830, loss = 5.61 (402.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 17:51:56.766762: step 1840, loss = 5.52 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:52:00.051971: step 1850, loss = 5.39 (394.8 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:52:03.357499: step 1860, loss = 5.50 (373.0 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 17:52:06.655063: step 1870, loss = 5.45 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:52:09.912019: step 1880, loss = 5.55 (405.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:52:13.205524: step 1890, loss = 5.41 (388.0 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03938\n",
      "2017-03-09 17:52:16.474308: step 1900, loss = 5.29 (378.9 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:52:19.743056: step 1910, loss = 5.41 (405.9 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 17:52:22.994541: step 1920, loss = 5.47 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:52:26.266257: step 1930, loss = 5.51 (405.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:52:29.547322: step 1940, loss = 5.62 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:52:32.827912: step 1950, loss = 5.52 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:52:36.078764: step 1960, loss = 5.40 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:52:39.390595: step 1970, loss = 5.44 (379.0 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:52:42.667266: step 1980, loss = 5.45 (385.5 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:52:45.931315: step 1990, loss = 5.42 (403.3 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05283\n",
      "2017-03-09 17:52:49.229088: step 2000, loss = 5.42 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:52:52.488346: step 2010, loss = 5.43 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:52:55.750582: step 2020, loss = 5.34 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:52:59.038226: step 2030, loss = 5.51 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:53:02.317296: step 2040, loss = 5.33 (386.6 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:53:05.613967: step 2050, loss = 5.55 (375.1 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:53:08.891065: step 2060, loss = 5.41 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:53:12.203060: step 2070, loss = 5.36 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:53:15.494938: step 2080, loss = 5.37 (373.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:53:18.782004: step 2090, loss = 5.51 (385.4 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04902\n",
      "2017-03-09 17:53:22.028174: step 2100, loss = 5.39 (392.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:53:25.291441: step 2110, loss = 5.33 (412.1 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 17:53:28.570712: step 2120, loss = 5.38 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:53:31.825973: step 2130, loss = 5.28 (379.7 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:53:35.104644: step 2140, loss = 5.38 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:53:38.371863: step 2150, loss = 5.32 (401.2 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:53:41.673909: step 2160, loss = 5.44 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:53:44.925429: step 2170, loss = 5.38 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 17:53:48.233800: step 2180, loss = 5.28 (377.5 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:53:51.542778: step 2190, loss = 5.36 (382.6 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04822\n",
      "2017-03-09 17:53:54.832746: step 2200, loss = 5.42 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:53:58.116112: step 2210, loss = 5.41 (373.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 17:54:01.385616: step 2220, loss = 5.41 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:54:04.643621: step 2230, loss = 5.43 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:54:07.908390: step 2240, loss = 5.43 (389.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 17:54:11.199643: step 2250, loss = 5.27 (369.2 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 17:54:14.475156: step 2260, loss = 5.37 (401.4 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:54:17.761773: step 2270, loss = 5.28 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:54:21.057127: step 2280, loss = 5.25 (370.6 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 17:54:24.341846: step 2290, loss = 5.35 (386.6 examples/sec; 0.331 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04895\n",
      "2017-03-09 17:54:27.630890: step 2300, loss = 5.23 (376.8 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 17:54:30.903718: step 2310, loss = 5.18 (392.8 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:54:34.176270: step 2320, loss = 5.32 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:54:37.450779: step 2330, loss = 5.31 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:54:40.730516: step 2340, loss = 5.25 (406.3 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 17:54:44.026916: step 2350, loss = 5.49 (383.4 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:54:47.273625: step 2360, loss = 5.38 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:54:50.554670: step 2370, loss = 5.33 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:54:53.847605: step 2380, loss = 5.31 (379.6 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 17:54:57.101328: step 2390, loss = 5.28 (394.1 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05261\n",
      "2017-03-09 17:55:00.390032: step 2400, loss = 5.40 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:55:03.678047: step 2410, loss = 5.46 (396.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:55:06.982512: step 2420, loss = 5.29 (396.2 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:55:10.256711: step 2430, loss = 5.31 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:55:13.518743: step 2440, loss = 5.25 (400.3 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:55:16.814392: step 2450, loss = 5.25 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:55:20.071441: step 2460, loss = 5.55 (402.7 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 17:55:23.379765: step 2470, loss = 5.34 (383.2 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:55:26.685022: step 2480, loss = 5.21 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:55:29.983473: step 2490, loss = 5.29 (397.5 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04057\n",
      "2017-03-09 17:55:33.278419: step 2500, loss = 5.26 (377.5 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:55:36.567263: step 2510, loss = 5.15 (370.6 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 17:55:39.830279: step 2520, loss = 5.31 (386.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:55:43.097021: step 2530, loss = 5.23 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:55:46.377448: step 2540, loss = 5.17 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:55:49.644957: step 2550, loss = 5.20 (399.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:55:52.939561: step 2560, loss = 5.34 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:55:56.218242: step 2570, loss = 5.26 (405.4 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:55:59.478247: step 2580, loss = 5.34 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:56:02.756595: step 2590, loss = 5.21 (400.0 examples/sec; 0.320 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05186\n",
      "2017-03-09 17:56:06.046226: step 2600, loss = 5.31 (380.9 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:56:09.309286: step 2610, loss = 5.37 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:56:12.613947: step 2620, loss = 5.30 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:56:15.900103: step 2630, loss = 5.24 (401.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:56:19.153477: step 2640, loss = 5.23 (415.1 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 17:56:22.463608: step 2650, loss = 5.28 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:56:25.757961: step 2660, loss = 5.23 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:56:29.051275: step 2670, loss = 5.16 (376.6 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 17:56:32.359168: step 2680, loss = 5.10 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:56:35.641817: step 2690, loss = 5.25 (380.3 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04131\n",
      "2017-03-09 17:56:38.926012: step 2700, loss = 5.13 (375.8 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:56:42.218478: step 2710, loss = 5.08 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 17:56:45.508547: step 2720, loss = 5.26 (405.5 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 17:56:48.756988: step 2730, loss = 5.28 (407.8 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 17:56:52.083038: step 2740, loss = 5.20 (378.1 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:56:55.352871: step 2750, loss = 5.27 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:56:58.625700: step 2760, loss = 5.14 (387.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:57:01.880652: step 2770, loss = 5.10 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:57:05.168551: step 2780, loss = 5.24 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:57:08.438373: step 2790, loss = 5.21 (391.2 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05007\n",
      "2017-03-09 17:57:11.713363: step 2800, loss = 5.19 (375.1 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:57:14.977515: step 2810, loss = 5.18 (385.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:57:18.266317: step 2820, loss = 5.21 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:57:21.544229: step 2830, loss = 5.30 (378.3 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:57:24.800084: step 2840, loss = 5.11 (385.9 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:57:28.115186: step 2850, loss = 5.21 (369.1 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 17:57:31.394518: step 2860, loss = 5.19 (388.0 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:57:34.656993: step 2870, loss = 5.19 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:57:37.937825: step 2880, loss = 5.21 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:57:41.203854: step 2890, loss = 5.06 (389.1 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0516\n",
      "2017-03-09 17:57:44.483104: step 2900, loss = 5.05 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:57:47.752166: step 2910, loss = 5.24 (377.4 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:57:51.011392: step 2920, loss = 5.40 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:57:54.312526: step 2930, loss = 5.23 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:57:57.591175: step 2940, loss = 5.14 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 17:58:00.882746: step 2950, loss = 5.19 (378.7 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 17:58:04.148046: step 2960, loss = 5.03 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 17:58:07.439875: step 2970, loss = 5.29 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 17:58:10.730528: step 2980, loss = 5.01 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:58:14.022577: step 2990, loss = 5.17 (389.5 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0468\n",
      "2017-03-09 17:58:17.302940: step 3000, loss = 5.12 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 17:58:20.569053: step 3010, loss = 5.12 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:58:23.851625: step 3020, loss = 5.08 (406.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 17:58:27.141361: step 3030, loss = 5.02 (375.7 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 17:58:30.419902: step 3040, loss = 5.15 (382.0 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:58:33.723964: step 3050, loss = 5.19 (377.5 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 17:58:36.984080: step 3060, loss = 4.99 (369.5 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 17:58:40.269073: step 3070, loss = 5.12 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:58:43.533379: step 3080, loss = 5.27 (403.9 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 17:58:46.818864: step 3090, loss = 5.02 (395.9 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05031\n",
      "2017-03-09 17:58:50.086072: step 3100, loss = 5.23 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:58:53.372857: step 3110, loss = 5.13 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 17:58:56.640454: step 3120, loss = 5.22 (388.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 17:58:59.895992: step 3130, loss = 5.21 (404.3 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 17:59:03.168228: step 3140, loss = 5.06 (382.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:59:06.468505: step 3150, loss = 5.16 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:59:09.745379: step 3160, loss = 5.18 (380.8 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:59:12.991983: step 3170, loss = 5.10 (403.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 17:59:16.268534: step 3180, loss = 5.17 (382.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:59:19.530434: step 3190, loss = 5.19 (390.5 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05342\n",
      "2017-03-09 17:59:22.836886: step 3200, loss = 5.13 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 17:59:26.118342: step 3210, loss = 5.14 (382.4 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 17:59:29.375872: step 3220, loss = 5.12 (398.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 17:59:32.677199: step 3230, loss = 5.18 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 17:59:35.966762: step 3240, loss = 5.14 (390.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 17:59:39.254943: step 3250, loss = 5.19 (400.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 17:59:42.519690: step 3260, loss = 5.14 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 17:59:45.802991: step 3270, loss = 5.31 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 17:59:49.092622: step 3280, loss = 5.09 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 17:59:52.380628: step 3290, loss = 4.97 (381.7 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04507\n",
      "2017-03-09 17:59:55.677956: step 3300, loss = 5.02 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 17:59:58.953196: step 3310, loss = 5.06 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:00:02.232058: step 3320, loss = 5.18 (425.2 examples/sec; 0.301 sec/batch)\n",
      "2017-03-09 18:00:05.562255: step 3330, loss = 4.88 (379.7 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:00:08.868796: step 3340, loss = 5.05 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:00:12.137601: step 3350, loss = 5.11 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:00:15.451152: step 3360, loss = 5.04 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:00:18.756458: step 3370, loss = 5.12 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:00:22.078854: step 3380, loss = 5.08 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:00:25.365327: step 3390, loss = 4.95 (375.0 examples/sec; 0.341 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03223\n",
      "2017-03-09 18:00:28.655625: step 3400, loss = 5.12 (378.9 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:00:31.923253: step 3410, loss = 5.29 (392.8 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:00:35.204441: step 3420, loss = 5.15 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:00:38.493689: step 3430, loss = 4.99 (401.4 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:00:41.769012: step 3440, loss = 5.13 (380.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:00:45.052397: step 3450, loss = 4.98 (382.4 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:00:48.363982: step 3460, loss = 5.03 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:00:51.624088: step 3470, loss = 5.21 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:00:54.920990: step 3480, loss = 5.14 (370.2 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:00:58.181215: step 3490, loss = 5.01 (393.5 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0484\n",
      "2017-03-09 18:01:01.461359: step 3500, loss = 5.10 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:01:04.725265: step 3510, loss = 5.06 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:01:07.969615: step 3520, loss = 5.03 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:01:11.253509: step 3530, loss = 5.03 (395.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:01:14.533951: step 3540, loss = 5.03 (378.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:01:17.834289: step 3550, loss = 4.97 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:01:21.102188: step 3560, loss = 5.04 (405.9 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:01:24.386310: step 3570, loss = 5.14 (384.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:01:27.657516: step 3580, loss = 4.93 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:01:30.936439: step 3590, loss = 4.90 (395.4 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05287\n",
      "2017-03-09 18:01:34.217296: step 3600, loss = 5.03 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:01:37.515710: step 3610, loss = 5.19 (379.5 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:01:40.784888: step 3620, loss = 5.10 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:01:44.071106: step 3630, loss = 5.04 (388.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:01:47.402131: step 3640, loss = 4.93 (376.2 examples/sec; 0.340 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3651 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:01:51.078726: step 3650, loss = 4.95 (172.9 examples/sec; 0.740 sec/batch)\n",
      "2017-03-09 18:01:54.010085: step 3660, loss = 4.91 (405.5 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:01:57.278746: step 3670, loss = 5.07 (398.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:02:00.532805: step 3680, loss = 5.17 (391.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:02:03.803071: step 3690, loss = 5.17 (386.0 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04366\n",
      "2017-03-09 18:02:07.072361: step 3700, loss = 5.02 (400.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:02:10.325920: step 3710, loss = 5.00 (416.1 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 18:02:13.642485: step 3720, loss = 4.96 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:02:16.963491: step 3730, loss = 4.88 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:02:20.247952: step 3740, loss = 4.86 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:02:23.518824: step 3750, loss = 5.14 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:02:26.802904: step 3760, loss = 4.96 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:02:30.100266: step 3770, loss = 4.89 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:02:33.403437: step 3780, loss = 4.98 (390.4 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:02:36.662891: step 3790, loss = 5.00 (390.1 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04206\n",
      "2017-03-09 18:02:39.943288: step 3800, loss = 4.82 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:02:43.210924: step 3810, loss = 5.02 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:02:46.496592: step 3820, loss = 4.95 (421.9 examples/sec; 0.303 sec/batch)\n",
      "2017-03-09 18:02:49.811143: step 3830, loss = 4.95 (382.4 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:02:53.070668: step 3840, loss = 5.04 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:02:56.361061: step 3850, loss = 4.89 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:02:59.649370: step 3860, loss = 4.98 (409.9 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:03:02.935857: step 3870, loss = 4.95 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:03:06.228350: step 3880, loss = 4.97 (386.6 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:03:09.532753: step 3890, loss = 4.91 (382.0 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04474\n",
      "2017-03-09 18:03:12.787120: step 3900, loss = 4.93 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:03:16.052527: step 3910, loss = 5.14 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:03:19.294269: step 3920, loss = 4.77 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:03:22.610446: step 3930, loss = 4.80 (371.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:03:25.872946: step 3940, loss = 4.92 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:03:29.155096: step 3950, loss = 4.93 (409.4 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:03:32.437844: step 3960, loss = 4.91 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:03:35.718457: step 3970, loss = 4.98 (389.3 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:03:38.994758: step 3980, loss = 4.94 (395.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:03:42.280354: step 3990, loss = 4.92 (390.2 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05284\n",
      "2017-03-09 18:03:45.543300: step 4000, loss = 4.84 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:03:48.834189: step 4010, loss = 5.10 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:03:52.125624: step 4020, loss = 4.91 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:03:55.420031: step 4030, loss = 4.96 (399.7 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:03:58.676625: step 4040, loss = 4.91 (400.2 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:04:01.982811: step 4050, loss = 4.75 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:04:05.289082: step 4060, loss = 4.81 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:04:08.585147: step 4070, loss = 4.94 (394.9 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:04:11.871185: step 4080, loss = 4.92 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:04:15.149333: step 4090, loss = 4.98 (377.6 examples/sec; 0.339 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04128\n",
      "2017-03-09 18:04:18.423545: step 4100, loss = 4.80 (374.7 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:04:21.696575: step 4110, loss = 4.83 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:04:24.953472: step 4120, loss = 5.09 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:04:28.239493: step 4130, loss = 4.86 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:04:31.493874: step 4140, loss = 4.92 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:04:34.781539: step 4150, loss = 4.88 (392.6 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:04:38.075113: step 4160, loss = 4.87 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:04:41.366149: step 4170, loss = 4.92 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:04:44.638492: step 4180, loss = 4.87 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:04:47.937564: step 4190, loss = 5.08 (386.0 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05051\n",
      "2017-03-09 18:04:51.205598: step 4200, loss = 4.99 (389.0 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:04:54.482056: step 4210, loss = 4.88 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:04:57.768187: step 4220, loss = 4.76 (389.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:05:01.067888: step 4230, loss = 4.80 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:05:04.389083: step 4240, loss = 4.82 (375.3 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:05:07.671393: step 4250, loss = 4.75 (382.0 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:05:10.929107: step 4260, loss = 4.88 (395.0 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:05:14.225085: step 4270, loss = 4.93 (403.1 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:05:17.513808: step 4280, loss = 4.91 (375.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:05:20.785951: step 4290, loss = 4.76 (407.5 examples/sec; 0.314 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04197\n",
      "2017-03-09 18:05:24.080884: step 4300, loss = 4.86 (377.3 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:05:27.322694: step 4310, loss = 4.86 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:05:30.605850: step 4320, loss = 4.96 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:05:33.894526: step 4330, loss = 4.81 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:05:37.174398: step 4340, loss = 4.90 (410.4 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:05:40.471055: step 4350, loss = 4.98 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:05:43.753452: step 4360, loss = 4.97 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:05:47.059310: step 4370, loss = 4.91 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:05:50.321129: step 4380, loss = 4.82 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:05:53.600891: step 4390, loss = 4.83 (370.7 examples/sec; 0.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0476\n",
      "2017-03-09 18:05:56.891522: step 4400, loss = 4.76 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:06:00.173163: step 4410, loss = 4.73 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:06:03.425378: step 4420, loss = 4.79 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:06:06.754050: step 4430, loss = 4.94 (375.2 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:06:10.057274: step 4440, loss = 4.75 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:06:13.312827: step 4450, loss = 4.86 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:06:16.569798: step 4460, loss = 4.90 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:06:19.824612: step 4470, loss = 4.72 (383.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:06:23.097808: step 4480, loss = 4.91 (399.1 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:06:26.376264: step 4490, loss = 4.81 (391.7 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05315\n",
      "2017-03-09 18:06:29.645372: step 4500, loss = 4.94 (375.4 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:06:32.921078: step 4510, loss = 4.84 (368.7 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 18:06:36.223831: step 4520, loss = 4.70 (378.3 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:06:39.504954: step 4530, loss = 4.75 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:06:42.779106: step 4540, loss = 4.78 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:06:46.066739: step 4550, loss = 4.72 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:06:49.335748: step 4560, loss = 4.69 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:06:52.616564: step 4570, loss = 4.70 (382.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:06:55.884908: step 4580, loss = 4.73 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:06:59.168238: step 4590, loss = 4.72 (403.5 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04708\n",
      "2017-03-09 18:07:02.463071: step 4600, loss = 4.67 (369.6 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:07:05.740585: step 4610, loss = 4.70 (372.0 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:07:09.001157: step 4620, loss = 4.74 (406.4 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:07:12.278218: step 4630, loss = 4.62 (404.5 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:07:15.558367: step 4640, loss = 4.78 (394.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:07:18.811856: step 4650, loss = 4.80 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:07:22.128276: step 4660, loss = 4.60 (380.6 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:07:25.397765: step 4670, loss = 4.72 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:07:28.691469: step 4680, loss = 4.70 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:07:31.975812: step 4690, loss = 4.81 (383.6 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04751\n",
      "2017-03-09 18:07:35.276908: step 4700, loss = 4.90 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:07:38.547158: step 4710, loss = 4.84 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:07:41.847151: step 4720, loss = 4.65 (396.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:07:45.126627: step 4730, loss = 4.72 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:07:48.402446: step 4740, loss = 4.66 (375.2 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:07:51.674396: step 4750, loss = 4.81 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:07:54.962886: step 4760, loss = 4.65 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:07:58.249596: step 4770, loss = 4.89 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:08:01.538447: step 4780, loss = 4.76 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:08:04.794205: step 4790, loss = 4.81 (412.3 examples/sec; 0.310 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05042\n",
      "2017-03-09 18:08:08.059312: step 4800, loss = 4.64 (369.3 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 18:08:11.289230: step 4810, loss = 4.66 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:08:14.570376: step 4820, loss = 4.75 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:08:17.868263: step 4830, loss = 4.76 (375.1 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:08:21.157464: step 4840, loss = 4.69 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:08:24.421226: step 4850, loss = 4.76 (403.6 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:08:27.685320: step 4860, loss = 4.79 (398.4 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:08:30.991469: step 4870, loss = 4.60 (400.2 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:08:34.265475: step 4880, loss = 4.69 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:08:37.542491: step 4890, loss = 4.79 (387.3 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05316\n",
      "2017-03-09 18:08:40.811850: step 4900, loss = 4.64 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:08:44.092214: step 4910, loss = 4.65 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:08:47.371653: step 4920, loss = 4.70 (405.0 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:08:50.632035: step 4930, loss = 4.71 (391.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:08:53.899063: step 4940, loss = 4.64 (410.9 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:08:57.176751: step 4950, loss = 4.51 (400.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:09:00.446847: step 4960, loss = 4.70 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:09:03.752268: step 4970, loss = 4.59 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:09:07.027232: step 4980, loss = 4.63 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:09:10.290665: step 4990, loss = 4.78 (382.1 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05421\n",
      "2017-03-09 18:09:13.553584: step 5000, loss = 4.57 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:09:16.822881: step 5010, loss = 4.68 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:09:20.103796: step 5020, loss = 4.73 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:09:23.371603: step 5030, loss = 4.64 (399.7 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:09:26.628113: step 5040, loss = 4.67 (399.9 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:09:29.927317: step 5050, loss = 4.71 (378.8 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:09:33.204970: step 5060, loss = 4.48 (402.6 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:09:36.465771: step 5070, loss = 4.57 (396.9 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:09:39.737308: step 5080, loss = 4.71 (373.1 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:09:43.001479: step 5090, loss = 4.83 (397.4 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05362\n",
      "2017-03-09 18:09:46.301772: step 5100, loss = 4.67 (378.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:09:49.569859: step 5110, loss = 4.62 (402.5 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:09:52.835948: step 5120, loss = 4.60 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:09:56.091480: step 5130, loss = 4.57 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:09:59.338578: step 5140, loss = 4.53 (413.4 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 18:10:02.614282: step 5150, loss = 4.73 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:10:05.888872: step 5160, loss = 4.68 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:10:09.180730: step 5170, loss = 4.86 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:10:12.438525: step 5180, loss = 4.55 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:10:15.710427: step 5190, loss = 4.69 (380.0 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.06037\n",
      "2017-03-09 18:10:18.977842: step 5200, loss = 4.71 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:10:22.249166: step 5210, loss = 4.69 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:10:25.536641: step 5220, loss = 4.59 (369.0 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 18:10:28.812976: step 5230, loss = 4.73 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:10:32.096680: step 5240, loss = 4.76 (370.3 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:10:35.386573: step 5250, loss = 4.52 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:10:38.674945: step 5260, loss = 4.70 (378.6 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:10:41.945636: step 5270, loss = 4.60 (390.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:10:45.212530: step 5280, loss = 4.74 (407.2 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:10:48.507879: step 5290, loss = 4.70 (372.5 examples/sec; 0.344 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05155\n",
      "2017-03-09 18:10:51.748119: step 5300, loss = 4.68 (398.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:10:55.025061: step 5310, loss = 4.71 (376.0 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:10:58.306982: step 5320, loss = 4.46 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:11:01.597811: step 5330, loss = 4.69 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:11:04.866165: step 5340, loss = 4.64 (413.9 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:11:08.125171: step 5350, loss = 4.70 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:11:11.419714: step 5360, loss = 4.62 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:11:14.689148: step 5370, loss = 4.50 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:11:17.986296: step 5380, loss = 4.66 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:11:21.236204: step 5390, loss = 4.61 (410.3 examples/sec; 0.312 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05188\n",
      "2017-03-09 18:11:24.514207: step 5400, loss = 4.66 (376.9 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:11:27.780188: step 5410, loss = 4.68 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:11:31.052932: step 5420, loss = 4.68 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:11:34.326446: step 5430, loss = 4.84 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:11:37.615502: step 5440, loss = 4.56 (381.0 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:11:40.868967: step 5450, loss = 4.83 (371.2 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 18:11:44.121466: step 5460, loss = 4.56 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:11:47.402999: step 5470, loss = 4.50 (384.7 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5481 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:11:51.060986: step 5480, loss = 4.62 (179.8 examples/sec; 0.712 sec/batch)\n",
      "2017-03-09 18:11:53.988876: step 5490, loss = 4.60 (403.1 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04982\n",
      "2017-03-09 18:11:57.304938: step 5500, loss = 4.58 (369.8 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:12:00.562713: step 5510, loss = 4.67 (410.9 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:12:03.841190: step 5520, loss = 4.53 (382.3 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:12:07.097750: step 5530, loss = 4.48 (399.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:12:10.382700: step 5540, loss = 4.66 (393.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:12:13.646401: step 5550, loss = 4.52 (410.2 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:12:16.932543: step 5560, loss = 4.50 (395.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:12:20.206451: step 5570, loss = 4.58 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:12:23.475179: step 5580, loss = 4.50 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:12:26.748863: step 5590, loss = 4.50 (382.2 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0557\n",
      "2017-03-09 18:12:30.029178: step 5600, loss = 4.69 (381.1 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:12:33.332835: step 5610, loss = 4.71 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:12:36.603956: step 5620, loss = 4.59 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:12:39.885587: step 5630, loss = 4.58 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:12:43.204707: step 5640, loss = 4.41 (403.7 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:12:46.470017: step 5650, loss = 4.61 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:12:49.737769: step 5660, loss = 4.55 (399.0 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:12:53.022767: step 5670, loss = 4.56 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:12:56.318377: step 5680, loss = 4.49 (388.0 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:12:59.618152: step 5690, loss = 4.60 (389.5 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04239\n",
      "2017-03-09 18:13:02.898147: step 5700, loss = 4.59 (388.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:13:06.173339: step 5710, loss = 4.60 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:13:09.471538: step 5720, loss = 4.51 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:13:12.744743: step 5730, loss = 4.53 (416.1 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 18:13:16.020715: step 5740, loss = 4.60 (380.8 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:13:19.288368: step 5750, loss = 4.57 (409.3 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:13:22.598499: step 5760, loss = 4.47 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:13:25.881883: step 5770, loss = 4.47 (395.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:13:29.128723: step 5780, loss = 4.45 (382.9 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:13:32.416875: step 5790, loss = 4.45 (411.2 examples/sec; 0.311 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04913\n",
      "2017-03-09 18:13:35.694284: step 5800, loss = 4.47 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:13:38.997348: step 5810, loss = 4.55 (375.8 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:13:42.296535: step 5820, loss = 4.39 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:13:45.583961: step 5830, loss = 4.47 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:13:48.874721: step 5840, loss = 4.44 (400.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:13:52.190297: step 5850, loss = 4.37 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:13:55.458377: step 5860, loss = 4.57 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:13:58.752093: step 5870, loss = 4.46 (388.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:14:02.024529: step 5880, loss = 4.41 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:14:05.279469: step 5890, loss = 4.46 (405.8 examples/sec; 0.315 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04159\n",
      "2017-03-09 18:14:08.571853: step 5900, loss = 4.73 (368.3 examples/sec; 0.348 sec/batch)\n",
      "2017-03-09 18:14:11.812172: step 5910, loss = 4.54 (405.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:14:15.084584: step 5920, loss = 4.51 (388.0 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:14:18.364400: step 5930, loss = 4.49 (404.3 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:14:21.644267: step 5940, loss = 4.47 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:14:24.924115: step 5950, loss = 4.44 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:14:28.222190: step 5960, loss = 4.43 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:14:31.496886: step 5970, loss = 4.60 (399.6 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:14:34.772182: step 5980, loss = 4.58 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:14:38.022527: step 5990, loss = 4.33 (394.0 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05276\n",
      "2017-03-09 18:14:41.330737: step 6000, loss = 4.55 (364.0 examples/sec; 0.352 sec/batch)\n",
      "2017-03-09 18:14:44.618348: step 6010, loss = 4.62 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:14:47.871702: step 6020, loss = 4.60 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:14:51.136593: step 6030, loss = 4.43 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:14:54.432994: step 6040, loss = 4.43 (374.4 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:14:57.702391: step 6050, loss = 4.40 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:15:00.964640: step 6060, loss = 4.49 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:15:04.227025: step 6070, loss = 4.53 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:15:07.504446: step 6080, loss = 4.50 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:15:10.782819: step 6090, loss = 4.41 (378.2 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05335\n",
      "2017-03-09 18:15:14.079670: step 6100, loss = 4.30 (388.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:15:17.319209: step 6110, loss = 4.51 (403.4 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:15:20.615220: step 6120, loss = 4.63 (369.5 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:15:23.905966: step 6130, loss = 4.58 (386.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:15:27.199336: step 6140, loss = 4.30 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:15:30.485020: step 6150, loss = 4.44 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:15:33.744108: step 6160, loss = 4.55 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:15:37.052653: step 6170, loss = 4.49 (376.5 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:15:40.339851: step 6180, loss = 4.59 (379.8 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:15:43.587214: step 6190, loss = 4.47 (392.1 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05139\n",
      "2017-03-09 18:15:46.851712: step 6200, loss = 4.53 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:15:50.121708: step 6210, loss = 4.42 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:15:53.388332: step 6220, loss = 4.33 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:15:56.662808: step 6230, loss = 4.33 (385.9 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:15:59.927794: step 6240, loss = 4.48 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:16:03.197510: step 6250, loss = 4.48 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:16:06.483957: step 6260, loss = 4.37 (394.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:16:09.765301: step 6270, loss = 4.45 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:16:13.042245: step 6280, loss = 4.35 (396.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:16:16.325144: step 6290, loss = 4.36 (404.7 examples/sec; 0.316 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0536\n",
      "2017-03-09 18:16:19.600418: step 6300, loss = 4.51 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:16:22.883617: step 6310, loss = 4.33 (400.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:16:26.169955: step 6320, loss = 4.23 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:16:29.437000: step 6330, loss = 4.23 (401.2 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:16:32.736278: step 6340, loss = 4.35 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:16:35.984104: step 6350, loss = 4.33 (401.6 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:16:39.263307: step 6360, loss = 4.45 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:16:42.553948: step 6370, loss = 4.46 (389.3 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:16:45.824814: step 6380, loss = 4.35 (408.3 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:16:49.085645: step 6390, loss = 4.53 (394.3 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05117\n",
      "2017-03-09 18:16:52.374214: step 6400, loss = 4.16 (373.2 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:16:55.657624: step 6410, loss = 4.52 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:16:58.957617: step 6420, loss = 4.34 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:17:02.258603: step 6430, loss = 4.44 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:17:05.538422: step 6440, loss = 4.53 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:17:08.796158: step 6450, loss = 4.27 (391.1 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:17:12.077137: step 6460, loss = 4.16 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:17:15.322421: step 6470, loss = 4.46 (391.3 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:17:18.618570: step 6480, loss = 4.11 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:17:21.880114: step 6490, loss = 4.37 (398.2 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04754\n",
      "2017-03-09 18:17:25.187888: step 6500, loss = 4.48 (408.2 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:17:28.477097: step 6510, loss = 4.45 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:17:31.754605: step 6520, loss = 4.43 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:17:35.061433: step 6530, loss = 4.28 (373.4 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:17:38.350803: step 6540, loss = 4.47 (372.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:17:41.625426: step 6550, loss = 4.40 (378.9 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:17:44.911755: step 6560, loss = 4.33 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:17:48.195711: step 6570, loss = 4.35 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:17:51.455170: step 6580, loss = 4.33 (407.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:17:54.705479: step 6590, loss = 4.43 (389.1 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04798\n",
      "2017-03-09 18:17:57.997735: step 6600, loss = 4.39 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:18:01.231716: step 6610, loss = 4.26 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:18:04.556105: step 6620, loss = 4.29 (382.4 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:18:07.831022: step 6630, loss = 4.43 (389.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:18:11.119348: step 6640, loss = 4.26 (403.9 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:18:14.406279: step 6650, loss = 4.48 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:18:17.669100: step 6660, loss = 4.41 (397.8 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:18:20.933999: step 6670, loss = 4.38 (379.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:18:24.218661: step 6680, loss = 4.22 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:18:27.487265: step 6690, loss = 4.27 (406.5 examples/sec; 0.315 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05055\n",
      "2017-03-09 18:18:30.777014: step 6700, loss = 4.48 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:18:34.046554: step 6710, loss = 4.27 (365.7 examples/sec; 0.350 sec/batch)\n",
      "2017-03-09 18:18:37.290924: step 6720, loss = 4.36 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:18:40.585818: step 6730, loss = 4.23 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:18:43.867784: step 6740, loss = 4.20 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:18:47.155080: step 6750, loss = 4.30 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:18:50.443095: step 6760, loss = 4.24 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:18:53.710670: step 6770, loss = 4.31 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:18:56.968824: step 6780, loss = 4.33 (382.3 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:19:00.221825: step 6790, loss = 4.29 (402.2 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05443\n",
      "2017-03-09 18:19:03.518099: step 6800, loss = 4.32 (371.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:19:06.786872: step 6810, loss = 4.19 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:19:10.063609: step 6820, loss = 4.41 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:19:13.331432: step 6830, loss = 4.11 (405.3 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:19:16.623390: step 6840, loss = 4.27 (393.8 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:19:19.919792: step 6850, loss = 4.25 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:19:23.203149: step 6860, loss = 4.54 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:19:26.493658: step 6870, loss = 4.30 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:19:29.785145: step 6880, loss = 4.31 (372.4 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:19:33.061734: step 6890, loss = 4.26 (372.8 examples/sec; 0.343 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04605\n",
      "2017-03-09 18:19:36.346534: step 6900, loss = 4.30 (386.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:19:39.606119: step 6910, loss = 4.21 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:19:42.884846: step 6920, loss = 4.21 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:19:46.134189: step 6930, loss = 4.19 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:19:49.427036: step 6940, loss = 4.29 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:19:52.717016: step 6950, loss = 4.44 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:19:55.979826: step 6960, loss = 4.30 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:19:59.286139: step 6970, loss = 4.42 (376.7 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:20:02.557504: step 6980, loss = 4.21 (373.4 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:20:05.822963: step 6990, loss = 4.42 (373.4 examples/sec; 0.343 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0563\n",
      "2017-03-09 18:20:09.065267: step 7000, loss = 4.36 (405.1 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:20:12.341454: step 7010, loss = 4.24 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:20:15.626178: step 7020, loss = 4.34 (399.1 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:20:18.913261: step 7030, loss = 4.29 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:20:22.211233: step 7040, loss = 4.22 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:20:25.466281: step 7050, loss = 4.24 (383.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:20:28.763531: step 7060, loss = 4.12 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:20:32.023315: step 7070, loss = 4.21 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:20:35.308845: step 7080, loss = 4.28 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:20:38.607909: step 7090, loss = 4.26 (395.1 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04547\n",
      "2017-03-09 18:20:41.900499: step 7100, loss = 4.54 (395.2 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:20:45.189643: step 7110, loss = 4.23 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:20:48.462146: step 7120, loss = 4.58 (391.1 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:20:51.763786: step 7130, loss = 4.37 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:20:55.047353: step 7140, loss = 4.37 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:20:58.329845: step 7150, loss = 4.11 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:21:01.625930: step 7160, loss = 4.07 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:21:04.907194: step 7170, loss = 4.05 (390.1 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:21:08.179433: step 7180, loss = 4.17 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:21:11.468892: step 7190, loss = 4.40 (409.3 examples/sec; 0.313 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0434\n",
      "2017-03-09 18:21:14.758697: step 7200, loss = 4.14 (386.6 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:21:18.061627: step 7210, loss = 4.23 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:21:21.331023: step 7220, loss = 4.10 (414.4 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:21:24.596659: step 7230, loss = 4.21 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:21:27.884098: step 7240, loss = 4.18 (393.8 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:21:31.167626: step 7250, loss = 4.15 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:21:34.444104: step 7260, loss = 4.17 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:21:37.718252: step 7270, loss = 4.20 (413.0 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 18:21:41.019470: step 7280, loss = 4.23 (372.3 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:21:44.293187: step 7290, loss = 4.18 (394.8 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04642\n",
      "2017-03-09 18:21:47.584350: step 7300, loss = 4.30 (386.8 examples/sec; 0.331 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7311 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:21:51.247678: step 7310, loss = 4.17 (174.4 examples/sec; 0.734 sec/batch)\n",
      "2017-03-09 18:21:54.284531: step 7320, loss = 4.27 (408.9 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:21:57.562214: step 7330, loss = 4.12 (381.9 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:22:00.851654: step 7340, loss = 4.19 (407.9 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:22:04.134781: step 7350, loss = 4.21 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:22:07.398384: step 7360, loss = 4.11 (404.1 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:22:10.676190: step 7370, loss = 4.23 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:22:13.948256: step 7380, loss = 4.14 (385.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:22:17.178818: step 7390, loss = 4.34 (409.5 examples/sec; 0.313 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.03964\n",
      "2017-03-09 18:22:20.484827: step 7400, loss = 4.34 (371.1 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 18:22:23.776090: step 7410, loss = 4.12 (403.7 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:22:27.033895: step 7420, loss = 4.24 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:22:30.331293: step 7430, loss = 4.04 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:22:33.596050: step 7440, loss = 3.95 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:22:36.885545: step 7450, loss = 4.19 (407.2 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:22:40.178261: step 7460, loss = 4.37 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:22:43.453090: step 7470, loss = 4.15 (373.9 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:22:46.705836: step 7480, loss = 4.27 (402.5 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:22:49.994491: step 7490, loss = 4.15 (397.5 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04818\n",
      "2017-03-09 18:22:53.289265: step 7500, loss = 4.12 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:22:56.538012: step 7510, loss = 4.27 (397.8 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:22:59.858438: step 7520, loss = 4.14 (394.8 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:23:03.142996: step 7530, loss = 4.12 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:23:06.432423: step 7540, loss = 3.96 (379.1 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:23:09.711240: step 7550, loss = 4.03 (380.6 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:23:12.975423: step 7560, loss = 4.26 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:23:16.256254: step 7570, loss = 4.36 (406.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:23:19.524964: step 7580, loss = 4.02 (378.8 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:23:22.792630: step 7590, loss = 4.21 (398.9 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04841\n",
      "2017-03-09 18:23:26.093363: step 7600, loss = 4.20 (373.0 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:23:29.354735: step 7610, loss = 4.14 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:23:32.624345: step 7620, loss = 4.02 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:23:35.931407: step 7630, loss = 4.21 (380.8 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:23:39.228765: step 7640, loss = 4.11 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:23:42.506284: step 7650, loss = 4.26 (404.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:23:45.793271: step 7660, loss = 4.26 (415.4 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 18:23:49.054630: step 7670, loss = 4.23 (399.6 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:23:52.337800: step 7680, loss = 4.02 (393.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:23:55.614929: step 7690, loss = 4.42 (392.5 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05154\n",
      "2017-03-09 18:23:58.865475: step 7700, loss = 4.29 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:24:02.153990: step 7710, loss = 4.17 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:24:05.427025: step 7720, loss = 4.07 (405.1 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:24:08.704207: step 7730, loss = 4.10 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:24:11.969240: step 7740, loss = 4.06 (408.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:24:15.232583: step 7750, loss = 4.15 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:24:18.480846: step 7760, loss = 4.14 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:24:21.738072: step 7770, loss = 3.94 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:24:24.995999: step 7780, loss = 3.99 (405.9 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:24:28.256943: step 7790, loss = 4.07 (370.9 examples/sec; 0.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.06297\n",
      "2017-03-09 18:24:31.511647: step 7800, loss = 4.09 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:24:34.791272: step 7810, loss = 4.08 (381.1 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:24:38.069102: step 7820, loss = 4.20 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:24:41.361560: step 7830, loss = 4.17 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:24:44.656963: step 7840, loss = 4.05 (398.4 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:24:47.917555: step 7850, loss = 4.27 (378.0 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:24:51.183896: step 7860, loss = 3.96 (373.7 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:24:54.454044: step 7870, loss = 3.95 (405.7 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:24:57.724507: step 7880, loss = 4.13 (401.5 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:25:00.999838: step 7890, loss = 4.16 (408.5 examples/sec; 0.313 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04907\n",
      "2017-03-09 18:25:04.310740: step 7900, loss = 4.15 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:25:07.585288: step 7910, loss = 4.29 (398.8 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:25:10.850573: step 7920, loss = 4.00 (408.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:25:14.146494: step 7930, loss = 4.01 (404.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:25:17.441257: step 7940, loss = 4.17 (376.9 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:25:20.666499: step 7950, loss = 4.20 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:25:23.929418: step 7960, loss = 4.21 (390.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:25:27.214894: step 7970, loss = 3.94 (376.8 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:25:30.496259: step 7980, loss = 4.13 (390.1 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:25:33.741064: step 7990, loss = 4.09 (395.8 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05539\n",
      "2017-03-09 18:25:37.038317: step 8000, loss = 4.17 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:25:40.324728: step 8010, loss = 4.13 (399.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:25:43.578902: step 8020, loss = 4.21 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:25:46.864372: step 8030, loss = 3.94 (400.6 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:25:50.150747: step 8040, loss = 4.24 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:25:53.426830: step 8050, loss = 4.02 (391.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:25:56.721181: step 8060, loss = 4.02 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:26:00.016029: step 8070, loss = 4.00 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:26:03.306693: step 8080, loss = 4.07 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:26:06.589300: step 8090, loss = 3.94 (392.0 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04798\n",
      "2017-03-09 18:26:09.845965: step 8100, loss = 4.16 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:26:13.105757: step 8110, loss = 4.04 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:26:16.355068: step 8120, loss = 3.93 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:26:19.655370: step 8130, loss = 3.93 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:26:22.921207: step 8140, loss = 3.99 (404.0 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:26:26.208207: step 8150, loss = 4.06 (390.5 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:26:29.476261: step 8160, loss = 4.02 (378.3 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:26:32.746750: step 8170, loss = 4.23 (375.4 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:26:35.998705: step 8180, loss = 3.84 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:26:39.266201: step 8190, loss = 3.96 (414.2 examples/sec; 0.309 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05809\n",
      "2017-03-09 18:26:42.546155: step 8200, loss = 3.99 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:26:45.832656: step 8210, loss = 4.02 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:26:49.112616: step 8220, loss = 4.05 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:26:52.416688: step 8230, loss = 4.05 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:26:55.710228: step 8240, loss = 3.89 (413.1 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 18:26:58.957853: step 8250, loss = 4.24 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:27:02.231462: step 8260, loss = 4.01 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:27:05.511093: step 8270, loss = 3.97 (402.5 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:27:08.794817: step 8280, loss = 3.93 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:27:12.046172: step 8290, loss = 4.31 (379.5 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05202\n",
      "2017-03-09 18:27:15.312043: step 8300, loss = 4.26 (361.6 examples/sec; 0.354 sec/batch)\n",
      "2017-03-09 18:27:18.614251: step 8310, loss = 3.87 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:27:21.883157: step 8320, loss = 3.99 (394.8 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:27:25.162436: step 8330, loss = 3.85 (387.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:27:28.439057: step 8340, loss = 4.08 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:27:31.690748: step 8350, loss = 4.14 (401.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:27:34.999775: step 8360, loss = 4.06 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:27:38.304078: step 8370, loss = 4.01 (399.6 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:27:41.553208: step 8380, loss = 4.06 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:27:44.872709: step 8390, loss = 3.99 (379.7 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04419\n",
      "2017-03-09 18:27:48.161247: step 8400, loss = 3.94 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:27:51.430447: step 8410, loss = 3.97 (400.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:27:54.715238: step 8420, loss = 3.85 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:27:57.980365: step 8430, loss = 3.99 (395.1 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:28:01.265526: step 8440, loss = 3.96 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:28:04.545702: step 8450, loss = 4.07 (405.1 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:28:07.840680: step 8460, loss = 3.85 (386.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:28:11.075169: step 8470, loss = 3.88 (406.3 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:28:14.340925: step 8480, loss = 3.86 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:28:17.587458: step 8490, loss = 3.89 (396.7 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0567\n",
      "2017-03-09 18:28:20.875815: step 8500, loss = 3.86 (377.3 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:28:24.133512: step 8510, loss = 3.98 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:28:27.405583: step 8520, loss = 3.93 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:28:30.690755: step 8530, loss = 4.12 (397.4 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:28:33.984848: step 8540, loss = 3.95 (387.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:28:37.270010: step 8550, loss = 3.98 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:28:40.539545: step 8560, loss = 3.97 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:28:43.822908: step 8570, loss = 4.06 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:28:47.126998: step 8580, loss = 3.94 (390.4 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:28:50.401898: step 8590, loss = 4.07 (383.1 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0466\n",
      "2017-03-09 18:28:53.699856: step 8600, loss = 4.03 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:28:56.938545: step 8610, loss = 3.85 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:29:00.205397: step 8620, loss = 3.88 (400.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:29:03.490226: step 8630, loss = 4.11 (378.0 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:29:06.784732: step 8640, loss = 3.87 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:29:10.092215: step 8650, loss = 4.02 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:29:13.355704: step 8660, loss = 3.94 (404.1 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:29:16.649264: step 8670, loss = 3.96 (385.5 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:29:19.908667: step 8680, loss = 3.91 (388.0 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:29:23.163670: step 8690, loss = 3.92 (392.3 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05377\n",
      "2017-03-09 18:29:26.447473: step 8700, loss = 4.12 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:29:29.739167: step 8710, loss = 4.01 (379.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:29:32.998407: step 8720, loss = 4.09 (414.8 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:29:36.265622: step 8730, loss = 3.99 (419.6 examples/sec; 0.305 sec/batch)\n",
      "2017-03-09 18:29:39.578721: step 8740, loss = 3.96 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:29:42.872412: step 8750, loss = 3.88 (375.0 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:29:46.146588: step 8760, loss = 3.99 (380.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:29:49.413707: step 8770, loss = 3.70 (400.2 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:29:52.693714: step 8780, loss = 3.88 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:29:55.968979: step 8790, loss = 3.83 (385.9 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05143\n",
      "2017-03-09 18:29:59.217662: step 8800, loss = 3.79 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:30:02.488409: step 8810, loss = 3.83 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:30:05.767632: step 8820, loss = 3.89 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:30:09.078854: step 8830, loss = 3.78 (360.5 examples/sec; 0.355 sec/batch)\n",
      "2017-03-09 18:30:12.332662: step 8840, loss = 3.83 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:30:15.616258: step 8850, loss = 3.91 (404.2 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:30:18.898031: step 8860, loss = 4.07 (374.3 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:30:22.187389: step 8870, loss = 4.02 (382.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:30:25.434998: step 8880, loss = 3.89 (403.7 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:30:28.726246: step 8890, loss = 3.82 (371.5 examples/sec; 0.345 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0493\n",
      "2017-03-09 18:30:32.011728: step 8900, loss = 3.78 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:30:35.288765: step 8910, loss = 3.93 (418.6 examples/sec; 0.306 sec/batch)\n",
      "2017-03-09 18:30:38.547203: step 8920, loss = 3.99 (405.9 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:30:41.846178: step 8930, loss = 3.97 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:30:45.073391: step 8940, loss = 3.74 (402.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:30:48.385206: step 8950, loss = 3.79 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:30:51.643553: step 8960, loss = 3.82 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:30:54.911783: step 8970, loss = 3.85 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:30:58.177046: step 8980, loss = 4.02 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:31:01.472776: step 8990, loss = 3.93 (378.6 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05544\n",
      "2017-03-09 18:31:04.740063: step 9000, loss = 3.91 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:31:08.020349: step 9010, loss = 3.87 (382.3 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:31:11.319119: step 9020, loss = 3.78 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:31:14.573866: step 9030, loss = 3.96 (402.3 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:31:17.863021: step 9040, loss = 3.81 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:31:21.162387: step 9050, loss = 3.91 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:31:24.435959: step 9060, loss = 4.00 (411.6 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 18:31:27.703871: step 9070, loss = 3.93 (403.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:31:30.968563: step 9080, loss = 4.07 (376.0 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:31:34.273455: step 9090, loss = 3.77 (384.6 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0499\n",
      "2017-03-09 18:31:37.528374: step 9100, loss = 3.93 (392.6 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:31:40.814897: step 9110, loss = 3.88 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:31:44.105020: step 9120, loss = 3.98 (380.7 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:31:47.371202: step 9130, loss = 3.94 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:31:50.644102: step 9140, loss = 4.04 (402.6 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9142 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:31:54.068747: step 9150, loss = 3.87 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:31:57.307480: step 9160, loss = 3.85 (406.8 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:32:00.605077: step 9170, loss = 3.94 (375.3 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:32:03.865504: step 9180, loss = 3.94 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:32:07.139944: step 9190, loss = 3.79 (385.0 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04106\n",
      "2017-03-09 18:32:10.413247: step 9200, loss = 4.18 (395.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:32:13.685637: step 9210, loss = 3.98 (397.4 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:32:16.981788: step 9220, loss = 3.85 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:32:20.226021: step 9230, loss = 3.75 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:32:23.520072: step 9240, loss = 3.87 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:32:26.806343: step 9250, loss = 3.94 (376.5 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:32:30.094524: step 9260, loss = 3.91 (368.7 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 18:32:33.353685: step 9270, loss = 3.87 (379.9 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:32:36.610381: step 9280, loss = 4.03 (406.6 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:32:39.915836: step 9290, loss = 3.82 (375.8 examples/sec; 0.341 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04975\n",
      "2017-03-09 18:32:43.201332: step 9300, loss = 3.88 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:32:46.492661: step 9310, loss = 3.82 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:32:49.813806: step 9320, loss = 3.86 (400.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:32:53.080450: step 9330, loss = 3.92 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:32:56.344270: step 9340, loss = 3.79 (413.1 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 18:32:59.632367: step 9350, loss = 3.83 (374.7 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:33:02.873881: step 9360, loss = 3.72 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:33:06.154927: step 9370, loss = 3.83 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:33:09.414443: step 9380, loss = 3.82 (406.8 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:33:12.710605: step 9390, loss = 3.95 (378.9 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0512\n",
      "2017-03-09 18:33:15.975265: step 9400, loss = 3.89 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:33:19.255154: step 9410, loss = 3.95 (396.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:33:22.538558: step 9420, loss = 3.76 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:33:25.792250: step 9430, loss = 3.82 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:33:29.066157: step 9440, loss = 3.66 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:33:32.317117: step 9450, loss = 3.88 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:33:35.592714: step 9460, loss = 3.78 (405.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:33:38.880179: step 9470, loss = 3.74 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:33:42.174002: step 9480, loss = 4.05 (402.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:33:45.463110: step 9490, loss = 3.97 (383.6 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05129\n",
      "2017-03-09 18:33:48.749582: step 9500, loss = 3.78 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:33:52.003791: step 9510, loss = 3.90 (398.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:33:55.272215: step 9520, loss = 3.78 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:33:58.561241: step 9530, loss = 3.90 (374.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:34:01.844711: step 9540, loss = 3.68 (388.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:34:05.093460: step 9550, loss = 3.67 (381.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:34:08.373090: step 9560, loss = 3.88 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:34:11.671638: step 9570, loss = 3.78 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:34:14.939349: step 9580, loss = 3.81 (381.1 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:34:18.232244: step 9590, loss = 3.93 (390.4 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05204\n",
      "2017-03-09 18:34:21.513245: step 9600, loss = 3.74 (378.1 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:34:24.788707: step 9610, loss = 3.74 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:34:28.071483: step 9620, loss = 3.91 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:34:31.322249: step 9630, loss = 3.94 (399.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:34:34.576265: step 9640, loss = 3.81 (406.6 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:34:37.877044: step 9650, loss = 3.78 (395.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:34:41.158200: step 9660, loss = 3.91 (405.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:34:44.434544: step 9670, loss = 3.65 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:34:47.706407: step 9680, loss = 3.75 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:34:50.983831: step 9690, loss = 3.60 (383.1 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05664\n",
      "2017-03-09 18:34:54.230759: step 9700, loss = 3.78 (393.6 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:34:57.525185: step 9710, loss = 3.81 (372.5 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:35:00.797563: step 9720, loss = 3.86 (393.9 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:35:04.045821: step 9730, loss = 3.77 (402.2 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:35:07.321455: step 9740, loss = 3.68 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:35:10.588205: step 9750, loss = 3.83 (377.9 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:35:13.884504: step 9760, loss = 3.78 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:35:17.162037: step 9770, loss = 3.73 (382.0 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:35:20.415243: step 9780, loss = 3.88 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:35:23.690707: step 9790, loss = 3.79 (393.2 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05401\n",
      "2017-03-09 18:35:26.974511: step 9800, loss = 3.73 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:35:30.240222: step 9810, loss = 3.69 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:35:33.522462: step 9820, loss = 3.85 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:35:36.805910: step 9830, loss = 3.62 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:35:40.073400: step 9840, loss = 3.79 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:35:43.340814: step 9850, loss = 3.67 (370.3 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:35:46.599098: step 9860, loss = 3.69 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:35:49.884951: step 9870, loss = 3.72 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:35:53.154014: step 9880, loss = 3.63 (417.6 examples/sec; 0.307 sec/batch)\n",
      "2017-03-09 18:35:56.438229: step 9890, loss = 4.03 (382.1 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05399\n",
      "2017-03-09 18:35:59.716540: step 9900, loss = 3.62 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:36:03.010411: step 9910, loss = 3.69 (365.6 examples/sec; 0.350 sec/batch)\n",
      "2017-03-09 18:36:06.294395: step 9920, loss = 3.68 (374.4 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:36:09.565064: step 9930, loss = 3.70 (403.2 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:36:12.831636: step 9940, loss = 3.94 (402.4 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:36:16.122928: step 9950, loss = 3.71 (396.5 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:36:19.428169: step 9960, loss = 3.98 (393.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:36:22.706542: step 9970, loss = 3.61 (379.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:36:25.951032: step 9980, loss = 3.72 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:36:29.228713: step 9990, loss = 3.77 (395.4 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05039\n",
      "2017-03-09 18:36:32.499538: step 10000, loss = 3.78 (383.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:36:35.743053: step 10010, loss = 4.00 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:36:39.022031: step 10020, loss = 3.64 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:36:42.293306: step 10030, loss = 3.72 (401.3 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:36:45.583007: step 10040, loss = 3.67 (399.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:36:48.851316: step 10050, loss = 3.65 (394.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:36:52.151214: step 10060, loss = 3.80 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:36:55.434718: step 10070, loss = 3.72 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:36:58.704200: step 10080, loss = 3.62 (382.4 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:37:01.954218: step 10090, loss = 3.60 (404.3 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.056\n",
      "2017-03-09 18:37:05.221977: step 10100, loss = 3.64 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:37:08.514273: step 10110, loss = 3.63 (377.0 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:37:11.790899: step 10120, loss = 3.60 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:37:15.050971: step 10130, loss = 3.59 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:37:18.319442: step 10140, loss = 3.76 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:37:21.598842: step 10150, loss = 3.76 (399.0 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:37:24.851442: step 10160, loss = 3.65 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:37:28.131918: step 10170, loss = 3.94 (405.3 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:37:31.392843: step 10180, loss = 3.64 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:37:34.660109: step 10190, loss = 3.81 (391.4 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05716\n",
      "2017-03-09 18:37:37.931915: step 10200, loss = 3.74 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:37:41.201415: step 10210, loss = 3.57 (410.7 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:37:44.476497: step 10220, loss = 3.78 (378.1 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:37:47.738391: step 10230, loss = 3.69 (402.7 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:37:51.011436: step 10240, loss = 3.83 (400.2 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:37:54.290217: step 10250, loss = 3.81 (405.3 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:37:57.590315: step 10260, loss = 3.71 (373.0 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:38:00.837442: step 10270, loss = 3.69 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:38:04.125289: step 10280, loss = 3.80 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:38:07.393799: step 10290, loss = 3.88 (394.3 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05531\n",
      "2017-03-09 18:38:10.661990: step 10300, loss = 3.74 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:38:13.936851: step 10310, loss = 3.77 (404.3 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:38:17.206551: step 10320, loss = 3.65 (393.6 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:38:20.475389: step 10330, loss = 3.69 (379.0 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:38:23.731860: step 10340, loss = 3.77 (396.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:38:27.001025: step 10350, loss = 3.61 (385.5 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:38:30.273441: step 10360, loss = 3.70 (373.2 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:38:33.539169: step 10370, loss = 3.53 (384.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:38:36.843213: step 10380, loss = 3.73 (380.6 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:38:40.092284: step 10390, loss = 3.80 (388.0 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05647\n",
      "2017-03-09 18:38:43.379603: step 10400, loss = 3.93 (380.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:38:46.633151: step 10410, loss = 3.63 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:38:49.928782: step 10420, loss = 3.65 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:38:53.198145: step 10430, loss = 3.74 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:38:56.444245: step 10440, loss = 3.60 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:38:59.716554: step 10450, loss = 3.62 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:39:03.004488: step 10460, loss = 3.64 (381.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:39:06.271242: step 10470, loss = 3.48 (385.2 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:39:09.564028: step 10480, loss = 3.58 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:39:12.850915: step 10490, loss = 3.82 (402.4 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0523\n",
      "2017-03-09 18:39:16.141646: step 10500, loss = 3.70 (369.8 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:39:19.398624: step 10510, loss = 3.63 (374.5 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:39:22.647475: step 10520, loss = 3.67 (400.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:39:25.929410: step 10530, loss = 3.85 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:39:29.185806: step 10540, loss = 3.73 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:39:32.449094: step 10550, loss = 3.57 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:39:35.752520: step 10560, loss = 3.66 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:39:39.032279: step 10570, loss = 3.60 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:39:42.332087: step 10580, loss = 3.58 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:39:45.611503: step 10590, loss = 3.61 (385.6 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05141\n",
      "2017-03-09 18:39:48.912917: step 10600, loss = 3.67 (386.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:39:52.147334: step 10610, loss = 3.70 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:39:55.413003: step 10620, loss = 3.65 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:39:58.687483: step 10630, loss = 3.73 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:40:01.983586: step 10640, loss = 3.72 (378.7 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:40:05.269076: step 10650, loss = 3.93 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:40:08.560510: step 10660, loss = 3.61 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:40:11.859882: step 10670, loss = 3.60 (384.1 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:40:15.116050: step 10680, loss = 3.58 (393.8 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:40:18.395654: step 10690, loss = 3.49 (391.0 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05284\n",
      "2017-03-09 18:40:21.671214: step 10700, loss = 3.58 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:40:24.933633: step 10710, loss = 3.62 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:40:28.203418: step 10720, loss = 3.80 (394.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:40:31.478066: step 10730, loss = 3.58 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:40:34.732122: step 10740, loss = 3.72 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:40:38.014970: step 10750, loss = 3.86 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:40:41.326361: step 10760, loss = 3.70 (360.2 examples/sec; 0.355 sec/batch)\n",
      "2017-03-09 18:40:44.578071: step 10770, loss = 3.60 (380.9 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:40:47.843125: step 10780, loss = 3.71 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:40:51.125668: step 10790, loss = 3.67 (405.4 examples/sec; 0.316 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05493\n",
      "2017-03-09 18:40:54.403527: step 10800, loss = 3.59 (377.8 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:40:57.673161: step 10810, loss = 3.65 (390.1 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:41:00.969014: step 10820, loss = 3.59 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:41:04.209717: step 10830, loss = 3.59 (406.4 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:41:07.462453: step 10840, loss = 3.56 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:41:10.734896: step 10850, loss = 3.69 (382.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:41:13.983940: step 10860, loss = 3.66 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:41:17.243531: step 10870, loss = 3.62 (399.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:41:20.520051: step 10880, loss = 3.52 (403.9 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:41:23.815139: step 10890, loss = 3.80 (381.5 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05798\n",
      "2017-03-09 18:41:27.106819: step 10900, loss = 3.54 (381.2 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:41:30.369552: step 10910, loss = 3.61 (393.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:41:33.663943: step 10920, loss = 3.67 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:41:36.957803: step 10930, loss = 3.57 (370.8 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 18:41:40.196009: step 10940, loss = 3.74 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:41:43.439887: step 10950, loss = 3.57 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:41:46.679446: step 10960, loss = 3.77 (405.4 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:41:49.946163: step 10970, loss = 3.69 (402.2 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10975 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:41:53.339941: step 10980, loss = 3.48 (395.3 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:41:56.616443: step 10990, loss = 3.59 (397.2 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04873\n",
      "2017-03-09 18:41:59.905502: step 11000, loss = 3.59 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:42:03.181179: step 11010, loss = 3.46 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:42:06.480952: step 11020, loss = 3.59 (377.9 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:42:09.728518: step 11030, loss = 3.75 (418.8 examples/sec; 0.306 sec/batch)\n",
      "2017-03-09 18:42:13.013646: step 11040, loss = 3.57 (381.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:42:16.270570: step 11050, loss = 3.85 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:42:19.531746: step 11060, loss = 3.61 (378.2 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:42:22.816172: step 11070, loss = 3.63 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:42:26.128032: step 11080, loss = 3.67 (387.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:42:29.420457: step 11090, loss = 3.70 (387.7 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05093\n",
      "2017-03-09 18:42:32.683599: step 11100, loss = 3.69 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:42:35.967035: step 11110, loss = 3.76 (380.9 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:42:39.261915: step 11120, loss = 3.89 (379.8 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:42:42.542071: step 11130, loss = 3.60 (399.8 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:42:45.844636: step 11140, loss = 3.53 (385.2 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:42:49.123230: step 11150, loss = 3.63 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:42:52.428992: step 11160, loss = 3.70 (373.7 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:42:55.716038: step 11170, loss = 3.61 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:42:58.993767: step 11180, loss = 3.61 (398.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:43:02.266543: step 11190, loss = 3.39 (374.1 examples/sec; 0.342 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04321\n",
      "2017-03-09 18:43:05.544470: step 11200, loss = 3.65 (385.3 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:43:08.797038: step 11210, loss = 3.47 (382.9 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:43:12.039001: step 11220, loss = 3.53 (408.1 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:43:15.319931: step 11230, loss = 3.57 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:43:18.622973: step 11240, loss = 3.56 (376.2 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:43:21.912006: step 11250, loss = 3.62 (381.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:43:25.169396: step 11260, loss = 3.54 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:43:28.455272: step 11270, loss = 3.55 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:43:31.733070: step 11280, loss = 3.66 (399.1 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:43:34.979682: step 11290, loss = 3.54 (398.8 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05565\n",
      "2017-03-09 18:43:38.270420: step 11300, loss = 3.41 (392.5 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:43:41.543635: step 11310, loss = 3.51 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:43:44.831108: step 11320, loss = 3.45 (385.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:43:48.105219: step 11330, loss = 3.43 (394.9 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:43:51.384609: step 11340, loss = 3.60 (393.9 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:43:54.677917: step 11350, loss = 3.48 (385.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:43:57.948573: step 11360, loss = 3.48 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:44:01.232309: step 11370, loss = 3.54 (363.7 examples/sec; 0.352 sec/batch)\n",
      "2017-03-09 18:44:04.493643: step 11380, loss = 3.56 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:44:07.768311: step 11390, loss = 3.47 (392.7 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04841\n",
      "2017-03-09 18:44:11.072708: step 11400, loss = 3.52 (376.7 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:44:14.331041: step 11410, loss = 3.46 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:44:17.627602: step 11420, loss = 3.70 (399.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:44:20.938578: step 11430, loss = 3.65 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:44:24.207395: step 11440, loss = 3.53 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:44:27.521497: step 11450, loss = 3.51 (371.7 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:44:30.786988: step 11460, loss = 3.57 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:44:34.089505: step 11470, loss = 3.56 (378.6 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:44:37.383393: step 11480, loss = 3.52 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:44:40.637870: step 11490, loss = 3.52 (402.3 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04135\n",
      "2017-03-09 18:44:43.953105: step 11500, loss = 3.47 (373.4 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:44:47.197621: step 11510, loss = 3.36 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:44:50.492462: step 11520, loss = 3.59 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:44:53.765307: step 11530, loss = 3.55 (407.5 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:44:57.028529: step 11540, loss = 3.62 (410.5 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:45:00.282211: step 11550, loss = 3.46 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:45:03.570517: step 11560, loss = 3.64 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:45:06.837784: step 11570, loss = 3.37 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:45:10.137999: step 11580, loss = 3.49 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:45:13.419988: step 11590, loss = 3.54 (387.6 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05563\n",
      "2017-03-09 18:45:16.679226: step 11600, loss = 3.44 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:45:19.969503: step 11610, loss = 3.50 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:45:23.249686: step 11620, loss = 3.45 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:45:26.487267: step 11630, loss = 3.39 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:45:29.792902: step 11640, loss = 3.75 (378.0 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:45:33.070263: step 11650, loss = 3.51 (379.5 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:45:36.348793: step 11660, loss = 3.37 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:45:39.637303: step 11670, loss = 3.61 (377.5 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:45:42.919853: step 11680, loss = 3.50 (400.0 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:45:46.220160: step 11690, loss = 3.54 (381.0 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04618\n",
      "2017-03-09 18:45:49.507802: step 11700, loss = 3.38 (374.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:45:52.793452: step 11710, loss = 3.38 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:45:56.074241: step 11720, loss = 3.42 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:45:59.348394: step 11730, loss = 3.58 (394.9 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:46:02.608298: step 11740, loss = 3.59 (382.3 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:46:05.886956: step 11750, loss = 3.50 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:46:09.188476: step 11760, loss = 3.56 (400.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:46:12.453973: step 11770, loss = 3.34 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:46:15.739374: step 11780, loss = 3.53 (374.5 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:46:18.991982: step 11790, loss = 3.48 (388.0 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05368\n",
      "2017-03-09 18:46:22.256174: step 11800, loss = 3.43 (374.5 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:46:25.510347: step 11810, loss = 3.57 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:46:28.757218: step 11820, loss = 3.63 (414.8 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:46:32.054464: step 11830, loss = 3.56 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:46:35.342090: step 11840, loss = 3.45 (409.7 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:46:38.614591: step 11850, loss = 3.33 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:46:41.906270: step 11860, loss = 3.36 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:46:45.165640: step 11870, loss = 3.28 (395.9 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:46:48.428238: step 11880, loss = 3.44 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:46:51.718324: step 11890, loss = 3.68 (392.1 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05468\n",
      "2017-03-09 18:46:54.992729: step 11900, loss = 3.41 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:46:58.231738: step 11910, loss = 3.61 (392.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:47:01.506692: step 11920, loss = 3.42 (372.1 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:47:04.786938: step 11930, loss = 3.27 (390.5 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:47:08.072883: step 11940, loss = 3.43 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:47:11.380821: step 11950, loss = 3.55 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:47:14.641235: step 11960, loss = 3.47 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:47:17.906877: step 11970, loss = 3.49 (391.3 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:47:21.205107: step 11980, loss = 3.47 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:47:24.468992: step 11990, loss = 3.43 (403.5 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05187\n",
      "2017-03-09 18:47:27.757970: step 12000, loss = 3.45 (365.4 examples/sec; 0.350 sec/batch)\n",
      "2017-03-09 18:47:31.039589: step 12010, loss = 3.52 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:47:34.320877: step 12020, loss = 3.42 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:47:37.616410: step 12030, loss = 3.40 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:47:40.902297: step 12040, loss = 3.44 (379.5 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:47:44.190348: step 12050, loss = 3.39 (379.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:47:47.462245: step 12060, loss = 3.61 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:47:50.747781: step 12070, loss = 3.48 (392.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:47:54.041835: step 12080, loss = 3.45 (407.6 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:47:57.338460: step 12090, loss = 3.32 (399.6 examples/sec; 0.320 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04542\n",
      "2017-03-09 18:48:00.594129: step 12100, loss = 3.32 (403.2 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:48:03.897226: step 12110, loss = 3.55 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:48:07.166910: step 12120, loss = 3.48 (395.9 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:48:10.421407: step 12130, loss = 3.46 (406.3 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:48:13.676332: step 12140, loss = 3.57 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:48:16.968203: step 12150, loss = 3.33 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:48:20.224818: step 12160, loss = 3.49 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:48:23.509955: step 12170, loss = 3.36 (379.9 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:48:26.789891: step 12180, loss = 3.50 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:48:30.083281: step 12190, loss = 3.41 (383.6 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05059\n",
      "2017-03-09 18:48:33.376114: step 12200, loss = 3.26 (391.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:48:36.641384: step 12210, loss = 3.35 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:48:39.912961: step 12220, loss = 3.39 (383.2 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:48:43.186834: step 12230, loss = 3.33 (400.0 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:48:46.449817: step 12240, loss = 3.47 (392.4 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:48:49.686525: step 12250, loss = 3.69 (403.4 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:48:52.948375: step 12260, loss = 3.29 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:48:56.227808: step 12270, loss = 3.51 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:48:59.500939: step 12280, loss = 3.59 (392.8 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:49:02.785817: step 12290, loss = 3.35 (391.5 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.06079\n",
      "2017-03-09 18:49:06.047686: step 12300, loss = 3.63 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:49:09.319834: step 12310, loss = 3.47 (381.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:49:12.587624: step 12320, loss = 3.67 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:49:15.843877: step 12330, loss = 3.35 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:49:19.122513: step 12340, loss = 3.40 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:49:22.406732: step 12350, loss = 3.33 (380.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:49:25.688521: step 12360, loss = 3.41 (387.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:49:28.949744: step 12370, loss = 3.48 (385.3 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:49:32.244793: step 12380, loss = 3.56 (413.7 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:49:35.517595: step 12390, loss = 3.37 (381.7 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05399\n",
      "2017-03-09 18:49:38.789959: step 12400, loss = 3.43 (381.9 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:49:42.080400: step 12410, loss = 3.61 (364.0 examples/sec; 0.352 sec/batch)\n",
      "2017-03-09 18:49:45.326332: step 12420, loss = 3.49 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:49:48.615477: step 12430, loss = 3.39 (372.8 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:49:51.857599: step 12440, loss = 3.35 (385.3 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:49:55.113995: step 12450, loss = 3.48 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:49:58.406768: step 12460, loss = 3.48 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:50:01.684468: step 12470, loss = 3.35 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:50:04.973306: step 12480, loss = 3.36 (394.9 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:50:08.260910: step 12490, loss = 3.49 (390.4 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05169\n",
      "2017-03-09 18:50:11.560731: step 12500, loss = 3.39 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:50:14.816392: step 12510, loss = 3.45 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:50:18.076273: step 12520, loss = 3.66 (407.7 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 18:50:21.336936: step 12530, loss = 3.44 (409.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:50:24.610706: step 12540, loss = 3.60 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:50:27.902278: step 12550, loss = 3.25 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:50:31.162262: step 12560, loss = 3.39 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:50:34.467192: step 12570, loss = 3.44 (375.4 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:50:37.736392: step 12580, loss = 3.39 (372.9 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:50:41.010564: step 12590, loss = 3.22 (383.2 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05073\n",
      "2017-03-09 18:50:44.337896: step 12600, loss = 3.36 (368.4 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 18:50:47.622270: step 12610, loss = 3.34 (409.1 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:50:50.901040: step 12620, loss = 3.40 (388.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:50:54.154742: step 12630, loss = 3.49 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:50:57.423198: step 12640, loss = 3.41 (400.9 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:51:00.699690: step 12650, loss = 3.22 (409.3 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:51:03.945385: step 12660, loss = 3.49 (399.7 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:51:07.216643: step 12670, loss = 3.22 (414.5 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:51:10.501122: step 12680, loss = 3.40 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:51:13.799402: step 12690, loss = 3.28 (397.3 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05551\n",
      "2017-03-09 18:51:17.065301: step 12700, loss = 3.36 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:51:20.355961: step 12710, loss = 3.44 (382.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:51:23.618900: step 12720, loss = 3.36 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:51:26.938079: step 12730, loss = 3.48 (378.7 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:51:30.182456: step 12740, loss = 3.53 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:51:33.463669: step 12750, loss = 3.28 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:51:36.732593: step 12760, loss = 3.34 (390.5 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:51:40.006469: step 12770, loss = 3.24 (402.3 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 18:51:43.282732: step 12780, loss = 3.43 (382.9 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:51:46.577530: step 12790, loss = 3.27 (378.4 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04828\n",
      "2017-03-09 18:51:49.871339: step 12800, loss = 3.29 (375.8 examples/sec; 0.341 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12806 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 18:51:53.243129: step 12810, loss = 3.25 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:51:56.513013: step 12820, loss = 3.51 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:51:59.788552: step 12830, loss = 3.28 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:52:03.075378: step 12840, loss = 3.32 (405.8 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:52:06.361600: step 12850, loss = 3.29 (412.8 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 18:52:09.628548: step 12860, loss = 3.32 (400.3 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:52:12.943849: step 12870, loss = 3.49 (409.2 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:52:16.210062: step 12880, loss = 3.37 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 18:52:19.490651: step 12890, loss = 3.43 (390.9 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.039\n",
      "2017-03-09 18:52:22.776755: step 12900, loss = 3.29 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:52:26.039449: step 12910, loss = 3.25 (382.2 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:52:29.328714: step 12920, loss = 3.26 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:52:32.613420: step 12930, loss = 3.23 (374.7 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:52:35.922158: step 12940, loss = 3.39 (399.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:52:39.203443: step 12950, loss = 3.35 (396.2 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:52:42.474567: step 12960, loss = 3.35 (404.0 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:52:45.767557: step 12970, loss = 3.24 (372.9 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:52:49.056145: step 12980, loss = 3.36 (380.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:52:52.311265: step 12990, loss = 3.60 (394.3 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04779\n",
      "2017-03-09 18:52:55.587320: step 13000, loss = 3.20 (387.3 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:52:58.856808: step 13010, loss = 3.40 (393.0 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:53:02.121130: step 13020, loss = 3.35 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:53:05.394552: step 13030, loss = 3.29 (383.4 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:53:08.662304: step 13040, loss = 3.22 (389.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:53:11.934784: step 13050, loss = 3.17 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:53:15.212110: step 13060, loss = 3.35 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:53:18.467111: step 13070, loss = 3.36 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:53:21.734707: step 13080, loss = 3.29 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:53:24.998636: step 13090, loss = 3.29 (379.8 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05664\n",
      "2017-03-09 18:53:28.302914: step 13100, loss = 3.30 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:53:31.584832: step 13110, loss = 3.29 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:53:34.868619: step 13120, loss = 3.46 (381.0 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:53:38.108758: step 13130, loss = 3.31 (396.5 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:53:41.393062: step 13140, loss = 3.16 (384.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:53:44.646264: step 13150, loss = 3.23 (382.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:53:47.922033: step 13160, loss = 3.39 (377.1 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:53:51.183122: step 13170, loss = 3.41 (385.2 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:53:54.461041: step 13180, loss = 3.33 (406.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:53:57.740425: step 13190, loss = 3.23 (386.8 examples/sec; 0.331 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05824\n",
      "2017-03-09 18:54:01.001918: step 13200, loss = 3.40 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:54:04.292161: step 13210, loss = 3.38 (400.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:54:07.554375: step 13220, loss = 3.48 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:54:10.830782: step 13230, loss = 3.44 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:54:14.102418: step 13240, loss = 3.36 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:54:17.381420: step 13250, loss = 3.13 (405.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:54:20.656983: step 13260, loss = 3.23 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:54:23.952611: step 13270, loss = 3.51 (384.1 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:54:27.219369: step 13280, loss = 3.47 (399.4 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:54:30.498554: step 13290, loss = 3.29 (398.7 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05251\n",
      "2017-03-09 18:54:33.763253: step 13300, loss = 3.29 (372.0 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 18:54:37.010221: step 13310, loss = 3.25 (378.0 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 18:54:40.289884: step 13320, loss = 3.40 (384.3 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:54:43.589435: step 13330, loss = 3.31 (376.9 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:54:46.836569: step 13340, loss = 3.43 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:54:50.116302: step 13350, loss = 3.34 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:54:53.394381: step 13360, loss = 3.41 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:54:56.674245: step 13370, loss = 3.30 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:54:59.938895: step 13380, loss = 3.24 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:55:03.209684: step 13390, loss = 3.28 (385.8 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05491\n",
      "2017-03-09 18:55:06.495285: step 13400, loss = 3.20 (406.3 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 18:55:09.786930: step 13410, loss = 3.32 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:55:13.068007: step 13420, loss = 3.46 (376.5 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:55:16.335068: step 13430, loss = 3.27 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:55:19.589311: step 13440, loss = 3.27 (414.9 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 18:55:22.874120: step 13450, loss = 3.37 (367.4 examples/sec; 0.348 sec/batch)\n",
      "2017-03-09 18:55:26.161894: step 13460, loss = 3.15 (404.8 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 18:55:29.448791: step 13470, loss = 3.17 (388.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:55:32.734673: step 13480, loss = 3.17 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 18:55:36.011197: step 13490, loss = 3.27 (379.1 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04856\n",
      "2017-03-09 18:55:39.298039: step 13500, loss = 3.28 (385.1 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:55:42.597288: step 13510, loss = 3.28 (378.7 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:55:45.854556: step 13520, loss = 3.39 (392.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:55:49.136866: step 13530, loss = 3.21 (386.4 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:55:52.438598: step 13540, loss = 3.24 (374.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:55:55.691249: step 13550, loss = 3.31 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:55:59.014989: step 13560, loss = 3.35 (375.4 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:56:02.284824: step 13570, loss = 3.17 (397.8 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:56:05.588609: step 13580, loss = 3.28 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:56:08.863680: step 13590, loss = 3.26 (395.0 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04419\n",
      "2017-03-09 18:56:12.147592: step 13600, loss = 3.18 (379.0 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 18:56:15.405420: step 13610, loss = 3.20 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:56:18.678920: step 13620, loss = 3.45 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:56:21.961741: step 13630, loss = 3.37 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:56:25.231023: step 13640, loss = 3.25 (396.2 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:56:28.530703: step 13650, loss = 3.12 (391.2 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:56:31.812406: step 13660, loss = 3.32 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:56:35.067722: step 13670, loss = 3.09 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:56:38.365511: step 13680, loss = 3.15 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:56:41.667767: step 13690, loss = 3.25 (389.1 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04626\n",
      "2017-03-09 18:56:44.974820: step 13700, loss = 3.24 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:56:48.255788: step 13710, loss = 3.39 (376.2 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:56:51.527185: step 13720, loss = 3.17 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:56:54.783166: step 13730, loss = 3.05 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:56:58.043228: step 13740, loss = 3.23 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 18:57:01.356212: step 13750, loss = 3.09 (370.1 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 18:57:04.585791: step 13760, loss = 3.25 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:57:07.844191: step 13770, loss = 3.35 (408.4 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:57:11.148248: step 13780, loss = 3.27 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:57:14.447717: step 13790, loss = 3.21 (382.4 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05314\n",
      "2017-03-09 18:57:17.730295: step 13800, loss = 3.18 (393.7 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:57:21.018859: step 13810, loss = 3.22 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:57:24.272183: step 13820, loss = 3.49 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:57:27.564647: step 13830, loss = 3.16 (398.8 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:57:30.846131: step 13840, loss = 3.18 (392.6 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:57:34.121429: step 13850, loss = 3.19 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:57:37.406402: step 13860, loss = 3.13 (373.0 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 18:57:40.668727: step 13870, loss = 3.36 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:57:43.967544: step 13880, loss = 3.17 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 18:57:47.245933: step 13890, loss = 3.10 (380.3 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04863\n",
      "2017-03-09 18:57:50.531373: step 13900, loss = 3.21 (408.9 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 18:57:53.800394: step 13910, loss = 3.30 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:57:57.080751: step 13920, loss = 3.05 (389.0 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:58:00.384081: step 13930, loss = 3.42 (398.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:58:03.684300: step 13940, loss = 3.32 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:58:06.970496: step 13950, loss = 3.21 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 18:58:10.266184: step 13960, loss = 3.26 (379.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:58:13.482963: step 13970, loss = 3.21 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:58:16.755364: step 13980, loss = 3.24 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:58:20.055222: step 13990, loss = 3.22 (391.2 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04636\n",
      "2017-03-09 18:58:23.358176: step 14000, loss = 3.17 (367.9 examples/sec; 0.348 sec/batch)\n",
      "2017-03-09 18:58:26.615736: step 14010, loss = 3.21 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:58:29.901149: step 14020, loss = 3.31 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 18:58:33.186437: step 14030, loss = 3.35 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 18:58:36.466880: step 14040, loss = 3.39 (380.7 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:58:39.739504: step 14050, loss = 3.25 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 18:58:43.043756: step 14060, loss = 3.05 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:58:46.309015: step 14070, loss = 3.23 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 18:58:49.569751: step 14080, loss = 3.23 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 18:58:52.854526: step 14090, loss = 3.11 (398.9 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05126\n",
      "2017-03-09 18:58:56.129125: step 14100, loss = 3.23 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 18:58:59.406700: step 14110, loss = 3.25 (399.6 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 18:59:02.715734: step 14120, loss = 3.13 (381.1 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 18:59:05.997532: step 14130, loss = 3.07 (365.2 examples/sec; 0.351 sec/batch)\n",
      "2017-03-09 18:59:09.265365: step 14140, loss = 3.22 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:59:12.515065: step 14150, loss = 3.18 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 18:59:15.814622: step 14160, loss = 3.08 (374.6 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 18:59:19.102761: step 14170, loss = 3.09 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 18:59:22.390009: step 14180, loss = 3.14 (376.6 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 18:59:25.651122: step 14190, loss = 3.26 (397.9 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04794\n",
      "2017-03-09 18:59:28.938716: step 14200, loss = 3.22 (375.3 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 18:59:32.209306: step 14210, loss = 3.09 (404.4 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 18:59:35.498046: step 14220, loss = 3.30 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 18:59:38.788692: step 14230, loss = 3.30 (382.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:59:42.055272: step 14240, loss = 3.07 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:59:45.338389: step 14250, loss = 3.42 (381.9 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 18:59:48.630599: step 14260, loss = 3.35 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 18:59:51.903772: step 14270, loss = 3.07 (410.5 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 18:59:55.174239: step 14280, loss = 3.21 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 18:59:58.440443: step 14290, loss = 3.40 (397.9 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04826\n",
      "2017-03-09 19:00:01.745169: step 14300, loss = 2.98 (370.2 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 19:00:05.036686: step 14310, loss = 3.08 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:00:08.313733: step 14320, loss = 3.12 (388.1 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:00:11.584211: step 14330, loss = 3.21 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:00:14.886640: step 14340, loss = 3.17 (382.2 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:00:18.155348: step 14350, loss = 3.21 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:00:21.415470: step 14360, loss = 3.14 (406.2 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:00:24.663243: step 14370, loss = 3.00 (415.3 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 19:00:27.952798: step 14380, loss = 3.05 (383.2 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:00:31.234454: step 14390, loss = 3.26 (382.4 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05091\n",
      "2017-03-09 19:00:34.520485: step 14400, loss = 3.23 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:00:37.784344: step 14410, loss = 3.05 (389.2 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:00:41.049898: step 14420, loss = 3.18 (372.2 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 19:00:44.342231: step 14430, loss = 3.27 (380.7 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:00:47.614942: step 14440, loss = 3.32 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:00:50.900421: step 14450, loss = 3.26 (387.0 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:00:54.167063: step 14460, loss = 3.07 (394.8 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:00:57.443815: step 14470, loss = 3.27 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:01:00.719327: step 14480, loss = 3.27 (385.7 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:01:04.021433: step 14490, loss = 3.24 (378.4 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0514\n",
      "2017-03-09 19:01:07.292509: step 14500, loss = 3.07 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:01:10.560978: step 14510, loss = 3.16 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:01:13.872608: step 14520, loss = 3.27 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:01:17.157945: step 14530, loss = 3.17 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:01:20.418891: step 14540, loss = 2.96 (394.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:01:23.701933: step 14550, loss = 3.04 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:01:26.975214: step 14560, loss = 3.12 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:01:30.259800: step 14570, loss = 2.94 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:01:33.534913: step 14580, loss = 3.05 (385.7 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:01:36.798818: step 14590, loss = 3.00 (396.7 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05225\n",
      "2017-03-09 19:01:40.056716: step 14600, loss = 3.09 (394.7 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:01:43.320893: step 14610, loss = 3.20 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:01:46.608940: step 14620, loss = 3.11 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:01:49.910120: step 14630, loss = 3.14 (380.0 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14636 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 19:01:53.247938: step 14640, loss = 3.27 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:01:56.516781: step 14650, loss = 3.03 (406.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:01:59.774538: step 14660, loss = 3.12 (405.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:02:03.047614: step 14670, loss = 3.29 (379.1 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 19:02:06.312503: step 14680, loss = 3.02 (403.2 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:02:09.576308: step 14690, loss = 3.29 (410.0 examples/sec; 0.312 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05025\n",
      "2017-03-09 19:02:12.839476: step 14700, loss = 3.00 (402.8 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:02:16.114480: step 14710, loss = 3.24 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:02:19.371405: step 14720, loss = 3.09 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:02:22.647520: step 14730, loss = 3.10 (383.4 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:02:25.918677: step 14740, loss = 3.12 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:02:29.198628: step 14750, loss = 3.17 (398.2 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:02:32.472730: step 14760, loss = 3.11 (403.9 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:02:35.748438: step 14770, loss = 3.11 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:02:39.031051: step 14780, loss = 3.19 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:02:42.316031: step 14790, loss = 3.14 (390.4 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05217\n",
      "2017-03-09 19:02:45.604735: step 14800, loss = 2.94 (387.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:02:48.891840: step 14810, loss = 3.10 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:02:52.153956: step 14820, loss = 3.06 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:02:55.429156: step 14830, loss = 2.98 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:02:58.701407: step 14840, loss = 2.96 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:03:02.015663: step 14850, loss = 3.15 (383.3 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:03:05.296508: step 14860, loss = 2.97 (380.5 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:03:08.591573: step 14870, loss = 3.06 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:03:11.871324: step 14880, loss = 3.19 (403.7 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:03:15.130242: step 14890, loss = 3.17 (377.6 examples/sec; 0.339 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04891\n",
      "2017-03-09 19:03:18.403163: step 14900, loss = 3.15 (386.5 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:03:21.668553: step 14910, loss = 3.18 (392.8 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:03:24.945267: step 14920, loss = 3.15 (381.3 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:03:28.245782: step 14930, loss = 3.08 (397.7 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:03:31.526294: step 14940, loss = 3.00 (406.3 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:03:34.770024: step 14950, loss = 3.17 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:03:38.026239: step 14960, loss = 3.15 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:03:41.287312: step 14970, loss = 3.20 (417.5 examples/sec; 0.307 sec/batch)\n",
      "2017-03-09 19:03:44.577015: step 14980, loss = 3.04 (406.1 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:03:47.839951: step 14990, loss = 3.17 (389.6 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05447\n",
      "2017-03-09 19:03:51.140562: step 15000, loss = 3.09 (388.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:03:54.425721: step 15010, loss = 3.15 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:03:57.683030: step 15020, loss = 3.13 (408.4 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 19:04:00.976721: step 15030, loss = 3.11 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:04:04.260376: step 15040, loss = 2.98 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:04:07.539450: step 15050, loss = 3.22 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:04:10.818192: step 15060, loss = 3.10 (401.3 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:04:14.077013: step 15070, loss = 2.86 (409.9 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 19:04:17.352379: step 15080, loss = 2.80 (387.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:04:20.631270: step 15090, loss = 3.19 (398.4 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05387\n",
      "2017-03-09 19:04:23.885899: step 15100, loss = 3.16 (395.5 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:04:27.169419: step 15110, loss = 3.14 (379.9 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:04:30.464179: step 15120, loss = 3.07 (380.4 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:04:33.716659: step 15130, loss = 3.16 (408.0 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 19:04:36.982577: step 15140, loss = 3.01 (393.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:04:40.265014: step 15150, loss = 3.01 (391.1 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:04:43.558479: step 15160, loss = 3.02 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:04:46.836482: step 15170, loss = 3.31 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:04:50.102860: step 15180, loss = 3.18 (396.5 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:04:53.411041: step 15190, loss = 3.14 (369.7 examples/sec; 0.346 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04889\n",
      "2017-03-09 19:04:56.686479: step 15200, loss = 3.07 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:04:59.959212: step 15210, loss = 3.13 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:05:03.224213: step 15220, loss = 3.03 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:05:06.482305: step 15230, loss = 2.94 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:05:09.737935: step 15240, loss = 3.00 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:05:13.006306: step 15250, loss = 3.20 (391.4 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:05:16.300340: step 15260, loss = 3.16 (382.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:05:19.556463: step 15270, loss = 3.06 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:05:22.783170: step 15280, loss = 2.98 (395.0 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:05:26.066238: step 15290, loss = 3.18 (402.3 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.06531\n",
      "2017-03-09 19:05:29.309695: step 15300, loss = 3.07 (395.2 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:05:32.550018: step 15310, loss = 3.01 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:05:35.810284: step 15320, loss = 3.23 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:05:39.074845: step 15330, loss = 3.04 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:05:42.349122: step 15340, loss = 3.01 (396.0 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:05:45.610240: step 15350, loss = 3.10 (411.1 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 19:05:48.912755: step 15360, loss = 3.05 (387.4 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:05:52.206306: step 15370, loss = 3.22 (380.9 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:05:55.455990: step 15380, loss = 3.17 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:05:58.764724: step 15390, loss = 3.07 (382.8 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05393\n",
      "2017-03-09 19:06:02.052846: step 15400, loss = 3.07 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:06:05.326018: step 15410, loss = 3.07 (381.3 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:06:08.625313: step 15420, loss = 3.07 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:06:11.889778: step 15430, loss = 3.03 (391.3 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:06:15.174176: step 15440, loss = 3.11 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:06:18.438861: step 15450, loss = 2.99 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:06:21.705420: step 15460, loss = 3.04 (375.3 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:06:24.982258: step 15470, loss = 3.10 (404.8 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:06:28.249608: step 15480, loss = 3.09 (396.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:06:31.511393: step 15490, loss = 3.04 (383.9 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05413\n",
      "2017-03-09 19:06:34.796629: step 15500, loss = 3.07 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:06:38.093170: step 15510, loss = 2.98 (399.8 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:06:41.346078: step 15520, loss = 3.03 (372.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 19:06:44.613970: step 15530, loss = 3.01 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:06:47.906931: step 15540, loss = 3.03 (406.5 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:06:51.161260: step 15550, loss = 2.95 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:06:54.428939: step 15560, loss = 3.04 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:06:57.715705: step 15570, loss = 2.92 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:07:00.971736: step 15580, loss = 3.04 (412.4 examples/sec; 0.310 sec/batch)\n",
      "2017-03-09 19:07:04.248695: step 15590, loss = 3.12 (392.4 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0541\n",
      "2017-03-09 19:07:07.537856: step 15600, loss = 2.88 (369.3 examples/sec; 0.347 sec/batch)\n",
      "2017-03-09 19:07:10.792852: step 15610, loss = 2.98 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:07:14.060985: step 15620, loss = 2.87 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:07:17.338113: step 15630, loss = 3.13 (384.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:07:20.607710: step 15640, loss = 3.07 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:07:23.875906: step 15650, loss = 2.91 (393.6 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:07:27.121361: step 15660, loss = 2.90 (384.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:07:30.406251: step 15670, loss = 3.12 (398.4 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:07:33.729769: step 15680, loss = 3.01 (373.2 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 19:07:37.013079: step 15690, loss = 2.92 (392.5 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05373\n",
      "2017-03-09 19:07:40.284946: step 15700, loss = 3.07 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:07:43.565511: step 15710, loss = 3.06 (405.0 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:07:46.853751: step 15720, loss = 2.89 (401.2 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:07:50.141748: step 15730, loss = 2.94 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:07:53.430061: step 15740, loss = 3.11 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:07:56.699271: step 15750, loss = 3.02 (387.9 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:07:59.974322: step 15760, loss = 3.03 (382.0 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:08:03.280206: step 15770, loss = 2.89 (380.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:08:06.548942: step 15780, loss = 3.05 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:08:09.839320: step 15790, loss = 2.94 (397.3 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04846\n",
      "2017-03-09 19:08:13.088696: step 15800, loss = 2.89 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:08:16.326004: step 15810, loss = 3.03 (406.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:08:19.618670: step 15820, loss = 3.06 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:08:22.899600: step 15830, loss = 2.97 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:08:26.152054: step 15840, loss = 2.93 (409.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 19:08:29.439806: step 15850, loss = 2.92 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:08:32.704062: step 15860, loss = 2.90 (387.5 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:08:35.999395: step 15870, loss = 2.99 (378.7 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 19:08:39.279980: step 15880, loss = 3.09 (376.8 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:08:42.557516: step 15890, loss = 3.09 (383.1 examples/sec; 0.334 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05353\n",
      "2017-03-09 19:08:45.838811: step 15900, loss = 2.97 (385.8 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:08:49.139447: step 15910, loss = 2.95 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:08:52.397414: step 15920, loss = 3.17 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:08:55.687860: step 15930, loss = 2.92 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:08:58.958304: step 15940, loss = 2.76 (404.2 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:09:02.249784: step 15950, loss = 2.82 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:09:05.529183: step 15960, loss = 2.98 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:09:08.824332: step 15970, loss = 2.84 (374.6 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 19:09:12.094971: step 15980, loss = 2.88 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:09:15.354188: step 15990, loss = 3.09 (398.1 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04869\n",
      "2017-03-09 19:09:18.637999: step 16000, loss = 2.86 (391.3 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:09:21.891994: step 16010, loss = 3.01 (401.1 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:09:25.163965: step 16020, loss = 2.98 (404.8 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:09:28.477952: step 16030, loss = 3.11 (377.6 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 19:09:31.772316: step 16040, loss = 2.95 (394.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:09:35.072228: step 16050, loss = 3.00 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:09:38.342176: step 16060, loss = 2.92 (382.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:09:41.625913: step 16070, loss = 2.93 (425.2 examples/sec; 0.301 sec/batch)\n",
      "2017-03-09 19:09:44.897472: step 16080, loss = 3.06 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:09:48.171276: step 16090, loss = 2.98 (401.6 examples/sec; 0.319 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0453\n",
      "2017-03-09 19:09:51.477007: step 16100, loss = 2.73 (371.4 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 19:09:54.759099: step 16110, loss = 2.90 (372.8 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 19:09:58.051254: step 16120, loss = 3.02 (375.6 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:10:01.331006: step 16130, loss = 3.01 (371.5 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 19:10:04.589255: step 16140, loss = 2.93 (397.8 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:10:07.886867: step 16150, loss = 3.00 (395.0 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:10:11.171355: step 16160, loss = 2.91 (401.0 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:10:14.429584: step 16170, loss = 2.85 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:10:17.687733: step 16180, loss = 3.12 (384.7 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:10:20.963464: step 16190, loss = 2.90 (386.1 examples/sec; 0.332 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05114\n",
      "2017-03-09 19:10:24.250695: step 16200, loss = 3.09 (398.7 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:10:27.560321: step 16210, loss = 2.92 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:10:30.812287: step 16220, loss = 2.84 (411.3 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 19:10:34.098423: step 16230, loss = 3.07 (388.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:10:37.357898: step 16240, loss = 3.00 (397.3 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:10:40.632148: step 16250, loss = 2.89 (396.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:10:43.926788: step 16260, loss = 3.00 (406.4 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:10:47.200430: step 16270, loss = 2.97 (399.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:10:50.495069: step 16280, loss = 3.02 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:10:53.764386: step 16290, loss = 2.99 (389.8 examples/sec; 0.328 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05093\n",
      "2017-03-09 19:10:57.026968: step 16300, loss = 2.89 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:11:00.299007: step 16310, loss = 2.98 (389.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:11:03.581407: step 16320, loss = 2.84 (392.7 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:11:06.876582: step 16330, loss = 3.02 (370.8 examples/sec; 0.345 sec/batch)\n",
      "2017-03-09 19:11:10.143459: step 16340, loss = 2.78 (391.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:11:13.414350: step 16350, loss = 3.06 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:11:16.706210: step 16360, loss = 2.83 (359.8 examples/sec; 0.356 sec/batch)\n",
      "2017-03-09 19:11:19.976125: step 16370, loss = 3.05 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:11:23.210415: step 16380, loss = 2.90 (390.4 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:11:26.489103: step 16390, loss = 2.97 (394.5 examples/sec; 0.324 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05463\n",
      "2017-03-09 19:11:29.764355: step 16400, loss = 2.90 (385.5 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:11:33.041839: step 16410, loss = 2.78 (419.5 examples/sec; 0.305 sec/batch)\n",
      "2017-03-09 19:11:36.327186: step 16420, loss = 2.93 (381.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:11:39.593247: step 16430, loss = 2.92 (388.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:11:42.891404: step 16440, loss = 2.93 (381.1 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:11:46.160352: step 16450, loss = 2.89 (394.0 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:11:49.431160: step 16460, loss = 3.12 (392.9 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16468 into cifar10VGGdropout_train/model.ckpt.\n",
      "2017-03-09 19:11:52.811332: step 16470, loss = 2.92 (571.9 examples/sec; 0.224 sec/batch)\n",
      "2017-03-09 19:11:56.094542: step 16480, loss = 2.98 (383.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:11:59.342496: step 16490, loss = 2.99 (384.0 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04363\n",
      "2017-03-09 19:12:02.621337: step 16500, loss = 2.86 (382.2 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:12:05.886596: step 16510, loss = 2.93 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:12:09.160873: step 16520, loss = 2.89 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:12:12.425247: step 16530, loss = 2.91 (384.0 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:12:15.671312: step 16540, loss = 3.04 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:12:18.952743: step 16550, loss = 2.79 (401.3 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:12:22.243050: step 16560, loss = 2.95 (397.6 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:12:25.496333: step 16570, loss = 2.98 (399.8 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:12:28.768218: step 16580, loss = 2.77 (385.9 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:12:32.024312: step 16590, loss = 2.94 (402.9 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0599\n",
      "2017-03-09 19:12:35.300978: step 16600, loss = 2.82 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:12:38.588121: step 16610, loss = 2.83 (394.1 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:12:41.863028: step 16620, loss = 3.14 (404.9 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:12:45.144361: step 16630, loss = 2.86 (401.6 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:12:48.421391: step 16640, loss = 2.86 (398.4 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:12:51.669996: step 16650, loss = 2.78 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:12:54.943799: step 16660, loss = 2.91 (385.3 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:12:58.191862: step 16670, loss = 2.90 (399.1 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:13:01.470068: step 16680, loss = 2.72 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:13:04.737934: step 16690, loss = 2.79 (396.8 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05527\n",
      "2017-03-09 19:13:08.031077: step 16700, loss = 3.01 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:13:11.332449: step 16710, loss = 3.02 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:13:14.574431: step 16720, loss = 2.85 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:13:17.882146: step 16730, loss = 2.93 (401.3 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:13:21.163492: step 16740, loss = 2.92 (396.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:13:24.452554: step 16750, loss = 2.94 (399.0 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:13:27.760489: step 16760, loss = 2.88 (375.0 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:13:31.039067: step 16770, loss = 2.70 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:13:34.324165: step 16780, loss = 2.85 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:13:37.620021: step 16790, loss = 2.91 (409.4 examples/sec; 0.313 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0407\n",
      "2017-03-09 19:13:40.919534: step 16800, loss = 2.86 (384.4 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:13:44.166792: step 16810, loss = 3.00 (382.5 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:13:47.448916: step 16820, loss = 3.00 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:13:50.736091: step 16830, loss = 3.02 (374.8 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 19:13:54.004908: step 16840, loss = 2.91 (380.0 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:13:57.235677: step 16850, loss = 2.99 (405.0 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:14:00.506725: step 16860, loss = 2.98 (408.0 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 19:14:03.765147: step 16870, loss = 2.99 (398.3 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:14:07.069332: step 16880, loss = 3.07 (402.3 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:14:10.344525: step 16890, loss = 2.94 (381.7 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05848\n",
      "2017-03-09 19:14:13.614258: step 16900, loss = 2.95 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:14:16.873377: step 16910, loss = 2.76 (408.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 19:14:20.129512: step 16920, loss = 3.01 (398.5 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:14:23.410090: step 16930, loss = 3.05 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:14:26.686695: step 16940, loss = 2.91 (397.2 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:14:29.947450: step 16950, loss = 3.00 (399.5 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:14:33.245280: step 16960, loss = 2.87 (384.6 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:14:36.526219: step 16970, loss = 2.90 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:14:39.770321: step 16980, loss = 2.81 (390.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:14:43.045033: step 16990, loss = 2.81 (382.6 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0566\n",
      "2017-03-09 19:14:46.331757: step 17000, loss = 2.80 (376.2 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:14:49.651929: step 17010, loss = 2.82 (383.6 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:14:52.930431: step 17020, loss = 3.01 (411.0 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 19:14:56.197170: step 17030, loss = 3.01 (403.1 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:14:59.441876: step 17040, loss = 2.93 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:15:02.720589: step 17050, loss = 3.05 (390.2 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:15:05.993799: step 17060, loss = 3.00 (405.6 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:15:09.291307: step 17070, loss = 3.00 (390.6 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:15:12.560048: step 17080, loss = 2.97 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 19:15:15.844145: step 17090, loss = 2.89 (388.6 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05223\n",
      "2017-03-09 19:15:19.093120: step 17100, loss = 2.70 (392.3 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:15:22.397697: step 17110, loss = 2.86 (388.8 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:15:25.659487: step 17120, loss = 2.84 (405.3 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:15:28.968700: step 17130, loss = 2.69 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:15:32.200068: step 17140, loss = 2.76 (399.6 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:15:35.463762: step 17150, loss = 2.75 (393.3 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:15:38.771943: step 17160, loss = 2.93 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:15:42.060424: step 17170, loss = 3.09 (392.5 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:15:45.310632: step 17180, loss = 2.74 (392.0 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:15:48.591420: step 17190, loss = 2.81 (396.7 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04926\n",
      "2017-03-09 19:15:51.887716: step 17200, loss = 2.97 (396.6 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:15:55.130513: step 17210, loss = 2.69 (384.5 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:15:58.380350: step 17220, loss = 3.01 (396.4 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:16:01.701264: step 17230, loss = 2.83 (395.4 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:16:04.982546: step 17240, loss = 2.84 (395.9 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:16:08.270503: step 17250, loss = 2.93 (387.8 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:16:11.533338: step 17260, loss = 3.03 (403.1 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:16:14.780767: step 17270, loss = 2.76 (397.9 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:16:18.071545: step 17280, loss = 2.68 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:16:21.359195: step 17290, loss = 2.75 (393.1 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0535\n",
      "2017-03-09 19:16:24.637521: step 17300, loss = 2.94 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:16:27.924686: step 17310, loss = 2.88 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:16:31.242585: step 17320, loss = 2.85 (373.7 examples/sec; 0.343 sec/batch)\n",
      "2017-03-09 19:16:34.533754: step 17330, loss = 2.99 (391.9 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:16:37.818960: step 17340, loss = 2.96 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:16:41.106225: step 17350, loss = 2.98 (383.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:16:44.396767: step 17360, loss = 2.88 (401.9 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:16:47.707569: step 17370, loss = 2.63 (364.2 examples/sec; 0.351 sec/batch)\n",
      "2017-03-09 19:16:50.975468: step 17380, loss = 2.93 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:16:54.252242: step 17390, loss = 2.94 (398.8 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04221\n",
      "2017-03-09 19:16:57.508488: step 17400, loss = 2.76 (399.1 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:17:00.781042: step 17410, loss = 2.84 (389.9 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:17:04.055279: step 17420, loss = 2.77 (401.0 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:17:07.354909: step 17430, loss = 2.77 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:17:10.610503: step 17440, loss = 2.86 (394.6 examples/sec; 0.324 sec/batch)\n",
      "2017-03-09 19:17:13.886019: step 17450, loss = 2.87 (386.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:17:17.138494: step 17460, loss = 2.82 (405.0 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:17:20.419341: step 17470, loss = 2.89 (383.1 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:17:23.663319: step 17480, loss = 2.89 (403.3 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:17:26.961571: step 17490, loss = 2.66 (388.0 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05606\n",
      "2017-03-09 19:17:30.229990: step 17500, loss = 3.01 (388.7 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:17:33.498561: step 17510, loss = 2.97 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:17:36.777006: step 17520, loss = 2.79 (390.1 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:17:40.080118: step 17530, loss = 2.75 (385.2 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:17:43.346080: step 17540, loss = 2.76 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:17:46.616687: step 17550, loss = 2.88 (384.2 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:17:49.864335: step 17560, loss = 2.80 (392.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:17:53.124413: step 17570, loss = 2.85 (377.2 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 19:17:56.393459: step 17580, loss = 2.77 (405.1 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:17:59.685795: step 17590, loss = 2.81 (384.4 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05417\n",
      "2017-03-09 19:18:02.973870: step 17600, loss = 2.79 (385.3 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:18:06.260273: step 17610, loss = 2.77 (375.7 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:18:09.519725: step 17620, loss = 2.90 (375.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:18:12.774448: step 17630, loss = 2.69 (397.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:18:16.057571: step 17640, loss = 2.84 (389.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:18:19.339661: step 17650, loss = 2.80 (383.0 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:18:22.620488: step 17660, loss = 2.92 (389.5 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:18:25.861000: step 17670, loss = 2.86 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:18:29.143545: step 17680, loss = 2.85 (400.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:18:32.435067: step 17690, loss = 2.75 (380.3 examples/sec; 0.337 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05077\n",
      "2017-03-09 19:18:35.750829: step 17700, loss = 2.75 (371.6 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 19:18:39.040292: step 17710, loss = 2.84 (374.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:18:42.315585: step 17720, loss = 2.86 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 19:18:45.596349: step 17730, loss = 2.95 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:18:48.892225: step 17740, loss = 2.77 (401.7 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:18:52.158015: step 17750, loss = 2.79 (397.5 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:18:55.440077: step 17760, loss = 2.82 (376.1 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:18:58.729510: step 17770, loss = 2.79 (374.3 examples/sec; 0.342 sec/batch)\n",
      "2017-03-09 19:19:01.984056: step 17780, loss = 2.75 (393.8 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:19:05.225005: step 17790, loss = 2.74 (395.7 examples/sec; 0.323 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05163\n",
      "2017-03-09 19:19:08.521603: step 17800, loss = 2.63 (375.3 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:19:11.768494: step 17810, loss = 2.78 (400.3 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:19:15.069564: step 17820, loss = 2.86 (388.6 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:19:18.352445: step 17830, loss = 2.83 (375.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:19:21.622208: step 17840, loss = 2.89 (381.4 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:19:24.901219: step 17850, loss = 2.74 (389.1 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:19:28.134896: step 17860, loss = 2.64 (414.8 examples/sec; 0.309 sec/batch)\n",
      "2017-03-09 19:19:31.439795: step 17870, loss = 2.79 (378.5 examples/sec; 0.338 sec/batch)\n",
      "2017-03-09 19:19:34.708104: step 17880, loss = 2.74 (390.3 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:19:38.001043: step 17890, loss = 2.67 (381.5 examples/sec; 0.336 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05379\n",
      "2017-03-09 19:19:41.267391: step 17900, loss = 2.87 (391.5 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:19:44.553447: step 17910, loss = 2.71 (376.4 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:19:47.811768: step 17920, loss = 2.86 (400.4 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:19:51.091357: step 17930, loss = 2.95 (402.0 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:19:54.377294: step 17940, loss = 2.76 (403.8 examples/sec; 0.317 sec/batch)\n",
      "2017-03-09 19:19:57.658149: step 17950, loss = 2.76 (396.3 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:20:00.930263: step 17960, loss = 2.97 (396.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:20:04.176330: step 17970, loss = 2.77 (393.2 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:20:07.437733: step 17980, loss = 2.67 (376.4 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:20:10.705944: step 17990, loss = 2.76 (397.1 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05547\n",
      "2017-03-09 19:20:13.994650: step 18000, loss = 2.80 (374.9 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:20:17.298995: step 18010, loss = 2.72 (382.3 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:20:20.562090: step 18020, loss = 2.80 (389.4 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:20:23.806463: step 18030, loss = 2.86 (389.0 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:20:27.071339: step 18040, loss = 2.74 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:20:30.377588: step 18050, loss = 2.90 (394.2 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:20:33.656650: step 18060, loss = 2.55 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:20:36.905388: step 18070, loss = 2.71 (400.0 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:20:40.184353: step 18080, loss = 2.89 (381.9 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:20:43.478326: step 18090, loss = 2.64 (387.0 examples/sec; 0.331 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05087\n",
      "2017-03-09 19:20:46.772160: step 18100, loss = 2.88 (377.4 examples/sec; 0.339 sec/batch)\n",
      "2017-03-09 19:20:50.063931: step 18110, loss = 2.71 (379.8 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:20:53.339519: step 18120, loss = 2.76 (398.9 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:20:56.608510: step 18130, loss = 2.71 (385.6 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:20:59.892569: step 18140, loss = 2.63 (379.7 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:21:03.171599: step 18150, loss = 2.76 (397.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:21:06.447770: step 18160, loss = 2.83 (391.6 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:21:09.712416: step 18170, loss = 2.77 (392.1 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:21:12.999787: step 18180, loss = 2.81 (390.0 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:21:16.289656: step 18190, loss = 2.71 (393.8 examples/sec; 0.325 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0461\n",
      "2017-03-09 19:21:19.600742: step 18200, loss = 2.95 (388.9 examples/sec; 0.329 sec/batch)\n",
      "2017-03-09 19:21:22.888213: step 18210, loss = 2.73 (393.8 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:21:26.154887: step 18220, loss = 2.95 (410.8 examples/sec; 0.312 sec/batch)\n",
      "2017-03-09 19:21:29.411434: step 18230, loss = 2.67 (406.6 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:21:32.688622: step 18240, loss = 2.64 (375.9 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:21:35.969482: step 18250, loss = 2.67 (396.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:21:39.254526: step 18260, loss = 2.69 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:21:42.534711: step 18270, loss = 2.90 (402.4 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:21:45.809791: step 18280, loss = 2.77 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:21:49.061371: step 18290, loss = 2.80 (398.7 examples/sec; 0.321 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18300 into cifar10VGGdropout_train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.02533\n",
      "2017-03-09 19:21:52.655306: step 18300, loss = 2.68 (592.0 examples/sec; 0.216 sec/batch)\n",
      "2017-03-09 19:21:55.716834: step 18310, loss = 2.81 (376.6 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:21:59.007527: step 18320, loss = 2.61 (387.6 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:22:02.260448: step 18330, loss = 2.91 (411.5 examples/sec; 0.311 sec/batch)\n",
      "2017-03-09 19:22:05.535804: step 18340, loss = 2.74 (371.8 examples/sec; 0.344 sec/batch)\n",
      "2017-03-09 19:22:08.796854: step 18350, loss = 2.66 (384.8 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:22:12.081115: step 18360, loss = 2.73 (387.7 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:22:15.330942: step 18370, loss = 2.93 (395.8 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:22:18.614578: step 18380, loss = 2.82 (407.4 examples/sec; 0.314 sec/batch)\n",
      "2017-03-09 19:22:21.908399: step 18390, loss = 2.71 (389.3 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0747\n",
      "2017-03-09 19:22:25.178659: step 18400, loss = 2.75 (392.9 examples/sec; 0.326 sec/batch)\n",
      "2017-03-09 19:22:28.490560: step 18410, loss = 2.67 (380.1 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:22:31.735113: step 18420, loss = 2.79 (389.8 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:22:34.990074: step 18430, loss = 2.65 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:22:38.270263: step 18440, loss = 2.80 (370.2 examples/sec; 0.346 sec/batch)\n",
      "2017-03-09 19:22:41.529896: step 18450, loss = 2.85 (388.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:22:44.828058: step 18460, loss = 2.84 (398.0 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:22:48.113042: step 18470, loss = 2.86 (396.1 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:22:51.379100: step 18480, loss = 2.50 (416.1 examples/sec; 0.308 sec/batch)\n",
      "2017-03-09 19:22:54.658739: step 18490, loss = 2.73 (379.1 examples/sec; 0.338 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05594\n",
      "2017-03-09 19:22:57.901824: step 18500, loss = 2.82 (385.0 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:23:01.186274: step 18510, loss = 2.69 (401.8 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:23:04.442487: step 18520, loss = 2.84 (419.7 examples/sec; 0.305 sec/batch)\n",
      "2017-03-09 19:23:07.722381: step 18530, loss = 2.59 (380.6 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:23:10.999993: step 18540, loss = 2.69 (394.4 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:23:14.251696: step 18550, loss = 2.62 (380.2 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:23:17.503932: step 18560, loss = 2.65 (393.5 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:23:20.767611: step 18570, loss = 2.89 (376.5 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:23:24.037608: step 18580, loss = 2.54 (404.7 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:23:27.304825: step 18590, loss = 2.63 (404.0 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05736\n",
      "2017-03-09 19:23:30.609455: step 18600, loss = 2.76 (406.8 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:23:33.879925: step 18610, loss = 2.64 (402.7 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:23:37.191463: step 18620, loss = 2.72 (362.8 examples/sec; 0.353 sec/batch)\n",
      "2017-03-09 19:23:40.444368: step 18630, loss = 2.69 (386.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:23:43.733498: step 18640, loss = 2.63 (381.7 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:23:46.989517: step 18650, loss = 2.84 (386.7 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:23:50.246357: step 18660, loss = 2.53 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:23:53.512688: step 18670, loss = 2.66 (388.0 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:23:56.793817: step 18680, loss = 2.77 (407.0 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:24:00.092556: step 18690, loss = 2.66 (389.2 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05126\n",
      "2017-03-09 19:24:03.383278: step 18700, loss = 2.67 (381.8 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:24:06.666819: step 18710, loss = 2.61 (391.7 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:24:09.967654: step 18720, loss = 2.75 (381.6 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:24:13.271705: step 18730, loss = 2.75 (398.1 examples/sec; 0.322 sec/batch)\n",
      "2017-03-09 19:24:16.530549: step 18740, loss = 2.68 (383.9 examples/sec; 0.333 sec/batch)\n",
      "2017-03-09 19:24:19.787694: step 18750, loss = 2.81 (386.6 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:24:23.045964: step 18760, loss = 2.65 (393.9 examples/sec; 0.325 sec/batch)\n",
      "2017-03-09 19:24:26.306307: step 18770, loss = 2.53 (387.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:24:29.570575: step 18780, loss = 2.64 (401.1 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:24:32.851373: step 18790, loss = 2.72 (389.0 examples/sec; 0.329 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05349\n",
      "2017-03-09 19:24:36.132790: step 18800, loss = 2.70 (402.9 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:24:39.418332: step 18810, loss = 2.70 (385.4 examples/sec; 0.332 sec/batch)\n",
      "2017-03-09 19:24:42.668794: step 18820, loss = 2.62 (383.5 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:24:45.963575: step 18830, loss = 2.65 (381.0 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:24:49.245868: step 18840, loss = 2.65 (380.7 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:24:52.497045: step 18850, loss = 2.70 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:24:55.764712: step 18860, loss = 2.77 (400.1 examples/sec; 0.320 sec/batch)\n",
      "2017-03-09 19:24:59.039024: step 18870, loss = 2.71 (395.7 examples/sec; 0.323 sec/batch)\n",
      "2017-03-09 19:25:02.307211: step 18880, loss = 2.69 (387.1 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:25:05.591236: step 18890, loss = 2.75 (404.7 examples/sec; 0.316 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05426\n",
      "2017-03-09 19:25:08.875578: step 18900, loss = 2.66 (398.6 examples/sec; 0.321 sec/batch)\n",
      "2017-03-09 19:25:12.147413: step 18910, loss = 2.76 (390.7 examples/sec; 0.328 sec/batch)\n",
      "2017-03-09 19:25:15.412091: step 18920, loss = 2.73 (387.3 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:25:18.671941: step 18930, loss = 2.71 (387.2 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:25:21.938987: step 18940, loss = 2.68 (382.8 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:25:25.219107: step 18950, loss = 2.66 (401.1 examples/sec; 0.319 sec/batch)\n",
      "2017-03-09 19:25:28.487565: step 18960, loss = 2.60 (417.7 examples/sec; 0.306 sec/batch)\n",
      "2017-03-09 19:25:31.761686: step 18970, loss = 2.56 (391.8 examples/sec; 0.327 sec/batch)\n",
      "2017-03-09 19:25:35.047441: step 18980, loss = 2.56 (388.2 examples/sec; 0.330 sec/batch)\n",
      "2017-03-09 19:25:38.291861: step 18990, loss = 2.63 (386.3 examples/sec; 0.331 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.05861\n",
      "2017-03-09 19:25:41.568430: step 19000, loss = 2.66 (382.1 examples/sec; 0.335 sec/batch)\n",
      "2017-03-09 19:25:44.841485: step 19010, loss = 2.70 (405.7 examples/sec; 0.315 sec/batch)\n",
      "2017-03-09 19:25:48.147448: step 19020, loss = 2.68 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:25:51.425079: step 19030, loss = 2.66 (402.2 examples/sec; 0.318 sec/batch)\n",
      "2017-03-09 19:25:54.688336: step 19040, loss = 2.75 (409.5 examples/sec; 0.313 sec/batch)\n",
      "2017-03-09 19:25:57.963574: step 19050, loss = 2.55 (376.8 examples/sec; 0.340 sec/batch)\n",
      "2017-03-09 19:26:01.247040: step 19060, loss = 2.68 (405.2 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:26:04.517236: step 19070, loss = 2.59 (381.0 examples/sec; 0.336 sec/batch)\n",
      "2017-03-09 19:26:07.781674: step 19080, loss = 2.59 (405.3 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:26:11.086580: step 19090, loss = 2.68 (387.5 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04966\n",
      "2017-03-09 19:26:14.358931: step 19100, loss = 2.79 (420.1 examples/sec; 0.305 sec/batch)\n",
      "2017-03-09 19:26:17.650056: step 19110, loss = 2.61 (383.7 examples/sec; 0.334 sec/batch)\n",
      "2017-03-09 19:26:20.902891: step 19120, loss = 2.48 (386.9 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:26:24.204922: step 19130, loss = 2.66 (375.7 examples/sec; 0.341 sec/batch)\n",
      "2017-03-09 19:26:27.504857: step 19140, loss = 2.72 (386.8 examples/sec; 0.331 sec/batch)\n",
      "2017-03-09 19:26:30.812021: step 19150, loss = 2.61 (379.3 examples/sec; 0.337 sec/batch)\n",
      "2017-03-09 19:26:34.061440: step 19160, loss = 2.71 (404.9 examples/sec; 0.316 sec/batch)\n",
      "2017-03-09 19:26:37.327751: step 19170, loss = 2.82 (392.7 examples/sec; 0.326 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = cifar_input.build_input('cifar10', 'cifar10/data_batch*', 128, 'train')\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    losses = loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = train(losses, global_step)\n",
    "\n",
    "    class _LoggerHook(tf.train.SessionRunHook):\n",
    "      \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "      def begin(self):\n",
    "        self._step = -1\n",
    "        f = open(\"log.txt\",'ab')\n",
    "        f.write('\\n\\n==== Run ===\\nInfo: VGG\\n')\n",
    "        f.close()\n",
    "\n",
    "      def before_run(self, run_context):\n",
    "        self._step += 1\n",
    "        self._start_time = time.time()\n",
    "        return tf.train.SessionRunArgs(losses)  # Asks for loss value.\n",
    "\n",
    "      def after_run(self, run_context, run_values):\n",
    "        duration = time.time() - self._start_time\n",
    "        loss_value = run_values.results\n",
    "        if self._step % 10 == 0:\n",
    "          num_examples_per_step = batch_size\n",
    "          examples_per_sec = num_examples_per_step / duration\n",
    "          sec_per_batch = float(duration)\n",
    "\n",
    "          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                        'sec/batch)')\n",
    "          print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "          f = open(\"log.txt\",'ab')\n",
    "          f.write('{0}: step {1}, loss = {2:.4f} ({3:.2f} examples/sec; {4:.2f} sec/batch)\\n'.format(datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "          f.close()\n",
    "            \n",
    "    with tf.train.MonitoredTrainingSession(checkpoint_dir=train_dir,\n",
    "                                           hooks=[tf.train.StopAtStepHook(last_step=max_steps),\n",
    "                                                  tf.train.NanTensorHook(losses),\n",
    "                                                  _LoggerHook()],\n",
    "                                           config=tf.ConfigProto(\n",
    "                                               log_device_placement=log_device_placement)) as mon_sess:\n",
    "        while not mon_sess.should_stop():\n",
    "            mon_sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "def evaluate():\n",
    "  eval_batch_count = 50\n",
    "  \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = cifar_input.build_input('cifar10', 'cifar10/test_batch.bin', 128, 'eval')\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = inference(images)\n",
    "    saver = tf.train.Saver()\n",
    "    #summary_writer = tf.summary.FileWriter(FLAGS.eval_dir)\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    tf.train.start_queue_runners(sess)\n",
    "\n",
    "    best_precision = 0.0\n",
    "    try:\n",
    "      ckpt_state = tf.train.get_checkpoint_state(train_dir)\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "      tf.logging.error('Cannot restore checkpoint: %s', e)\n",
    "    if not (ckpt_state and ckpt_state.model_checkpoint_path):\n",
    "      tf.logging.info('No model to eval yet at %s', train_dir)\n",
    "    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
    "\n",
    "    total_prediction, correct_prediction = 0, 0\n",
    "    for _ in six.moves.range(eval_batch_count):\n",
    "      (predictions, truth) = sess.run(\n",
    "          [logits, labels])\n",
    "\n",
    "      truth = np.argmax(truth, axis=1)\n",
    "      predictions = np.argmax(predictions, axis=1)\n",
    "      correct_prediction += np.sum(truth == predictions)\n",
    "      total_prediction += predictions.shape[0]\n",
    "\n",
    "    precision = 1.0 * correct_prediction / total_prediction\n",
    "    best_precision = max(precision, best_precision)\n",
    "\n",
    "    tf.logging.info('precision: %.3f, best precision: %.3f' %\n",
    "                    (precision, best_precision))\n",
    "    f = open(\"log.txt\",'ab')\n",
    "    f.write('precision: {0}, best precision: {1}'.format(precision, best_precision))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
